{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML with the Experts: School Budgets - solutions.ipynb","provenance":[],"collapsed_sections":["E9oTVv0LjOXv"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"VNk1ZWkCi_mm","colab_type":"code","colab":{}},"source":["# https://www.datacamp.com/courses/machine-learning-with-the-experts-school-budgets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"awKua-Z3V496","colab_type":"code","colab":{}},"source":["# to import all \n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import Imputer, FunctionTransformer, MaxAbsScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import chi2, SelectKBest\n","from sklearn.feature_extraction.text import HashingVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-JWL6XEjJlT","colab_type":"text"},"source":["## 1. Exploring the raw data"]},{"cell_type":"markdown","metadata":{"id":"f33CkzPKja1-","colab_type":"text"},"source":["#### Introducing the challenge\n","\n","Now it's time to check out the dataset! You'll use pandas (which has been pre-imported as pd) to load your data into a DataFrame and then do some Exploratory Data Analysis (EDA) of it.\n","\n","The training data is available as TrainingData.csv. Your first task is to load it into a DataFrame in the IPython Shell using pd.read_csv() along with the keyword argument index_col=0.\n","\n","Use methods such as .info(), .head(), and .tail() to explore the budget data and the properties of the features and labels."]},{"cell_type":"code","metadata":{"id":"QkGVDVGxCFrS","colab_type":"code","outputId":"39597bda-89be-4d23-a082-21d7884330ad","executionInfo":{"status":"ok","timestamp":1558431771315,"user_tz":-480,"elapsed":1547,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["df = pd.read_csv('/content/ML with experts.csv', header=None, index_col=0)\n","df.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>198</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplemental *</td>\n","      <td>NaN</td>\n","      <td>Operation and Maintenance of Plant Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Non-Certificated Salaries And Wages</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Care and Upkeep of Building Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-8290.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I CARRYOVER</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>Student Transportation</td>\n","      <td>NO_LABEL</td>\n","      <td>Shared Services</td>\n","      <td>Non-School</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Other Non-Compensation</td>\n","      <td>NO_LABEL</td>\n","      <td>PreK-12 Operating</td>\n","      <td>REPAIR AND MAINTENANCE SERVICES</td>\n","      <td>NaN</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ADMIN. SERVICES</td>\n","      <td>NaN</td>\n","      <td>STUDENT TRANSPORT SERVICE</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>618.00</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>General Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>Teacher Compensation</td>\n","      <td>Instruction</td>\n","      <td>School Reported</td>\n","      <td>School</td>\n","      <td>Unspecified</td>\n","      <td>Teacher</td>\n","      <td>Base Salary/Compensation</td>\n","      <td>Non PreK</td>\n","      <td>PreK-12 Operating</td>\n","      <td>Personal Services - Teachers</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TCHER 5TH GRADE</td>\n","      <td>NaN</td>\n","      <td>Regular Instruction</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TEACHER</td>\n","      <td>49800.00</td>\n","      <td>Instruction - Regular</td>\n","      <td>General Purpose School</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>931</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Instruction</td>\n","      <td>Instruction And Curriculum</td>\n","      <td>NaN</td>\n","      <td>-1.02</td>\n","      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n","      <td>General Operating Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1524</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplies and Materials</td>\n","      <td>NaN</td>\n","      <td>Community Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Supplies And Materials</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Other Community Services *</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2300.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I PI+HOMELESS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          1   ...                   25\n","0                             ...                     \n","198                 NO_LABEL  ...    TITLE I CARRYOVER\n","209   Student Transportation  ...                  NaN\n","750     Teacher Compensation  ...                  NaN\n","931                 NO_LABEL  ...                  NaN\n","1524                NO_LABEL  ...  TITLE I PI+HOMELESS\n","\n","[5 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"_JKR7DcyjLXr","colab_type":"code","outputId":"c859e571-6c09-4c48-f3e1-c5ffe96c0ddd","executionInfo":{"status":"ok","timestamp":1558431775844,"user_tz":-480,"elapsed":762,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df.shape # (1560, 25)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1560, 25)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"h0Ub-3_ZIdRn","colab_type":"code","colab":{}},"source":["df.columns = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type',\n","       'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status',\n","       'Object_Description', 'Text_2', 'SubFund_Description',\n","       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n","       'Location_Description', 'FTE', 'Function_Description',\n","       'Facility_or_Department', 'Position_Extra', 'Total',\n","       'Program_Description', 'Fund_Description', 'Text_1']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzqMRbCFB0Zs","colab_type":"code","outputId":"8c60937a-7c95-4461-8821-c85d7a2b6ec8","executionInfo":{"status":"ok","timestamp":1558419851797,"user_tz":-480,"elapsed":789,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["df.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Function</th>\n","      <th>Use</th>\n","      <th>Sharing</th>\n","      <th>Reporting</th>\n","      <th>Student_Type</th>\n","      <th>Position_Type</th>\n","      <th>Object_Type</th>\n","      <th>Pre_K</th>\n","      <th>Operating_Status</th>\n","      <th>Object_Description</th>\n","      <th>Text_2</th>\n","      <th>SubFund_Description</th>\n","      <th>Job_Title_Description</th>\n","      <th>Text_3</th>\n","      <th>Text_4</th>\n","      <th>Sub_Object_Description</th>\n","      <th>Location_Description</th>\n","      <th>FTE</th>\n","      <th>Function_Description</th>\n","      <th>Facility_or_Department</th>\n","      <th>Position_Extra</th>\n","      <th>Total</th>\n","      <th>Program_Description</th>\n","      <th>Fund_Description</th>\n","      <th>Text_1</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>198</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplemental *</td>\n","      <td>NaN</td>\n","      <td>Operation and Maintenance of Plant Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Non-Certificated Salaries And Wages</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Care and Upkeep of Building Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-8290.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I CARRYOVER</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>Student Transportation</td>\n","      <td>NO_LABEL</td>\n","      <td>Shared Services</td>\n","      <td>Non-School</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Other Non-Compensation</td>\n","      <td>NO_LABEL</td>\n","      <td>PreK-12 Operating</td>\n","      <td>REPAIR AND MAINTENANCE SERVICES</td>\n","      <td>NaN</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ADMIN. SERVICES</td>\n","      <td>NaN</td>\n","      <td>STUDENT TRANSPORT SERVICE</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>618.00</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>General Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>Teacher Compensation</td>\n","      <td>Instruction</td>\n","      <td>School Reported</td>\n","      <td>School</td>\n","      <td>Unspecified</td>\n","      <td>Teacher</td>\n","      <td>Base Salary/Compensation</td>\n","      <td>Non PreK</td>\n","      <td>PreK-12 Operating</td>\n","      <td>Personal Services - Teachers</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TCHER 5TH GRADE</td>\n","      <td>NaN</td>\n","      <td>Regular Instruction</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TEACHER</td>\n","      <td>49800.00</td>\n","      <td>Instruction - Regular</td>\n","      <td>General Purpose School</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>931</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Instruction</td>\n","      <td>Instruction And Curriculum</td>\n","      <td>NaN</td>\n","      <td>-1.02</td>\n","      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n","      <td>General Operating Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1524</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplies and Materials</td>\n","      <td>NaN</td>\n","      <td>Community Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Supplies And Materials</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Other Community Services *</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2300.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I PI+HOMELESS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Function  ...               Text_1\n","0                             ...                     \n","198                 NO_LABEL  ...    TITLE I CARRYOVER\n","209   Student Transportation  ...                  NaN\n","750     Teacher Compensation  ...                  NaN\n","931                 NO_LABEL  ...                  NaN\n","1524                NO_LABEL  ...  TITLE I PI+HOMELESS\n","\n","[5 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"7WOsvL-bjdqh","colab_type":"text"},"source":["#### Exploring the data"]},{"cell_type":"markdown","metadata":{"id":"h-SGb-wEZus2","colab_type":"text"},"source":["Print summary statistics of the numeric columns in the DataFrame df using the .describe() method."]},{"cell_type":"code","metadata":{"id":"P6xfYFXmZoR-","colab_type":"code","outputId":"fede0b86-d8e8-4af0-aebf-14503069f720","executionInfo":{"status":"ok","timestamp":1558419881089,"user_tz":-480,"elapsed":955,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# Print the summary statistics\n","print(df.describe())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              FTE         Total\n","count  449.000000  1.542000e+03\n","mean     0.493532  1.447254e+04\n","std      0.452844  7.915691e+04\n","min     -0.002369 -1.040000e+06\n","25%      0.004310  1.110000e+02\n","50%      0.440000  7.060000e+02\n","75%      1.000000  5.345000e+03\n","max      1.047222  1.370000e+06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYxNq5NTZpgN","colab_type":"code","colab":{}},"source":["# Import matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBnoO0x1ZquO","colab_type":"code","outputId":"6029c0b1-da11-4a91-eb31-ec5baaed3250","executionInfo":{"status":"ok","timestamp":1558368085678,"user_tz":-480,"elapsed":988,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":354}},"source":["# Create the histogram\n","plt.hist(df['FTE'].dropna())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([173.,  30.,  11.,   7.,  21.,   5.,   8.,   7.,  12., 175.]),\n"," array([-0.002369 ,  0.1025901,  0.2075492,  0.3125083,  0.4174674,\n","         0.5224265,  0.6273856,  0.7323447,  0.8373038,  0.9422629,\n","         1.047222 ]),\n"," <a list of 10 Patch objects>)"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD6pJREFUeJzt3X+s3XV9x/HnS6ouUzbQXgkBugum\nmKHbqt4Ql02HwznABXRbWJup4IhVJ8t+mC2oyTAuJjpFEzMHK6EBF0VQhjYRp4Q5yRbrLMK6gqIF\ni7arbQWHbjgm5b0/7rfu2N32np7vOff0fnw+kpP7/X6+v94f7uV1P/dzvufbVBWSpHY9YdoFSJIm\ny6CXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNW7FtAsAWLlyZc3Ozk67DElaVu64\n445vV9XMYvsdFUE/OzvLli1bpl2GJC0rSR4YZj+nbiSpcQa9JDXOoJekxhn0ktQ4g16SGrdo0CfZ\nmGRvkm0DbTckuat77UhyV9c+m+T7A9uummTxkqTFDXN75bXAXwEfPNBQVb9zYDnJFcDDA/vfV1Vr\nxlWgJKmfRYO+qm5PMrvQtiQBLgR+dbxlSZLGpe8c/QuBPVX1tYG2U5PcmeRzSV7Y8/ySpJ76fjJ2\nHXD9wPpuYFVVPZjk+cDHkzy7qr578IFJ1gPrAVatWtWzDEka3exln5zatXe882UTv8bII/okK4Df\nBG440FZVj1bVg93yHcB9wOkLHV9VG6pqrqrmZmYWfVSDJGlEfUb0LwG+UlU7DzQkmQEeqqr9SU4D\nVgP396xxUdP6bbwUv4klqa9hbq+8Hvg88KwkO5Nc0m1ay49O2wC8CNja3W75MeD1VfXQOAuWJB2Z\nYe66WXeI9osXaLsJuKl/WZKkcfGTsZLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG\nGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxB\nL0mNWzTok2xMsjfJtoG2tyXZleSu7nXewLY3J9me5N4kvz6pwiVJwxlmRH8tcM4C7e+rqjXd6xaA\nJGcAa4Fnd8f8dZJjxlWsJOnILRr0VXU78NCQ57sA+EhVPVpVXwe2A2f2qE+S1FOfOfpLk2ztpnaO\n79pOAr45sM/Oru3/SbI+yZYkW/bt29ejDEnS4Ywa9FcCzwTWALuBK470BFW1oarmqmpuZmZmxDIk\nSYsZKeirak9V7a+qx4Gr+b/pmV3AKQO7nty1SZKmZKSgT3LiwOorgAN35GwC1iZ5cpJTgdXAv/Qr\nUZLUx4rFdkhyPXAWsDLJTuBy4Kwka4ACdgCvA6iqu5PcCNwDPAa8sar2T6Z0SdIwFg36qlq3QPM1\nh9n/HcA7+hQlSRofPxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+gl\nqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGLRr0STYm2Ztk\n20Dbu5N8JcnWJDcnOa5rn03y/SR3da+rJlm8JGlxw4zorwXOOajtVuA5VfXzwFeBNw9su6+q1nSv\n14+nTEnSqBYN+qq6HXjooLbPVNVj3epm4OQJ1CZJGoNxzNH/HvCpgfVTk9yZ5HNJXjiG80uSeljR\n5+AkbwUeAz7UNe0GVlXVg0meD3w8ybOr6rsLHLseWA+watWqPmVIkg5j5BF9kouB3wB+t6oKoKoe\nraoHu+U7gPuA0xc6vqo2VNVcVc3NzMyMWoYkaREjBX2Sc4A/A86vqkcG2meSHNMtnwasBu4fR6GS\npNEsOnWT5HrgLGBlkp3A5czfZfNk4NYkAJu7O2xeBLw9yQ+Ax4HXV9VDC55YkrQkFg36qlq3QPM1\nh9j3JuCmvkVJksbHT8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJ\napxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNW6ooE+y\nMcneJNsG2p6W5NYkX+u+Ht+1J8n7k2xPsjXJ8yZVvCRpccOO6K8Fzjmo7TLgtqpaDdzWrQOcC6zu\nXuuBK/uXKUka1VBBX1W3Aw8d1HwBcF23fB3w8oH2D9a8zcBxSU4cR7GSpCPXZ47+hKra3S1/Czih\nWz4J+ObAfju7th+RZH2SLUm27Nu3r0cZkqTDGcubsVVVQB3hMRuqaq6q5mZmZsZRhiRpAX2Cfs+B\nKZnu696ufRdwysB+J3dtkqQp6BP0m4CLuuWLgE8MtL+6u/vmBcDDA1M8kqQltmKYnZJcD5wFrEyy\nE7gceCdwY5JLgAeAC7vdbwHOA7YDjwCvGXPNkqQjMFTQV9W6Q2w6e4F9C3hjn6IkSePjJ2MlqXEG\nvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BL\nUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4of5x8IUkeRZww0DTacCfA8cBrwX2de1vqapb\nRq5QktTLyEFfVfcCawCSHAPsAm4GXgO8r6reM5YKJUm9jGvq5mzgvqp6YEznkySNybiCfi1w/cD6\npUm2JtmY5PgxXUOSNILeQZ/kScD5wEe7piuBZzI/rbMbuOIQx61PsiXJln379i20iyRpDMYxoj8X\n+FJV7QGoqj1Vtb+qHgeuBs5c6KCq2lBVc1U1NzMzM4YyJEkLGUfQr2Ng2ibJiQPbXgFsG8M1JEkj\nGvmuG4AkTwF+DXjdQPNfJlkDFLDjoG2SpCXWK+ir6r+Apx/U9qpeFUmSxspPxkpS4wx6SWqcQS9J\njTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4\ng16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bkXfEyTZAXwP2A88VlVzSZ4G3ADMAjuAC6vqO32v\nJUk6cuMa0b+4qtZU1Vy3fhlwW1WtBm7r1iVJUzCpqZsLgOu65euAl0/oOpKkRYwj6Av4TJI7kqzv\n2k6oqt3d8reAE8ZwHUnSCHrP0QO/XFW7kjwDuDXJVwY3VlUlqYMP6n4prAdYtWrVGMqQJC2k94i+\nqnZ1X/cCNwNnAnuSnAjQfd27wHEbqmququZmZmb6liFJOoReQZ/kKUmOPbAMvBTYBmwCLup2uwj4\nRJ/rSJJG13fq5gTg5iQHzvXhqvr7JF8EbkxyCfAAcGHP60iSRtQr6KvqfuAXFmh/EDi7z7klSePh\nJ2MlqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiD\nXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDWu778Z+2Nt9rJPTuW6O975sqlcV9Ly5Ihekhpn0EtS\n40YO+iSnJPlsknuS3J3kD7v2tyXZleSu7nXe+MqVJB2pPnP0jwFvqqovJTkWuCPJrd2291XVe/qX\nJ0nqa+Sgr6rdwO5u+XtJvgycNK7CJEnjMZY5+iSzwHOBL3RNlybZmmRjkuMPccz6JFuSbNm3b984\nypAkLaB30Cd5KnAT8EdV9V3gSuCZwBrmR/xXLHRcVW2oqrmqmpuZmelbhiTpEHoFfZInMh/yH6qq\nvwOoqj1Vtb+qHgeuBs7sX6YkaVR97roJcA3w5ap670D7iQO7vQLYNnp5kqS++tx180vAq4B/S3JX\n1/YWYF2SNUABO4DX9apQktRLn7tu/gnIAptuGb0caWHTetwE+MgJLX9+MlaSGmfQS1LjDHpJapxB\nL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4/o860aSxmqaj7pomUG/DPncF0lHwqkbSWqc\nQS9JjXPqRjpKOUWncXFEL0mNc0SvI+JdET8e/D63xRG9JDXOEb20CEe3Wu4c0UtS4yYW9EnOSXJv\nku1JLpvUdSRJhzeRoE9yDPAB4FzgDGBdkjMmcS1J0uFNakR/JrC9qu6vqv8BPgJcMKFrSZIOY1JB\nfxLwzYH1nV2bJGmJTe2umyTrgfXd6n8mubfH6VYC3+5f1VHPfrbFfrZlpH7mXb2u+TPD7DSpoN8F\nnDKwfnLX9kNVtQHYMI6LJdlSVXPjONfRzH62xX625Wju56Smbr4IrE5yapInAWuBTRO6liTpMCYy\noq+qx5JcCnwaOAbYWFV3T+JakqTDm9gcfVXdAtwyqfMfZCxTQMuA/WyL/WzLUdvPVNW0a5AkTZCP\nQJCkxi2roF/ssQpJnpzkhm77F5LMLn2V/Q3Rzz9Jck+SrUluSzLULVZHm2Efk5Hkt5JUkqPyjobF\nDNPPJBd239O7k3x4qWschyF+blcl+WySO7uf3fOmUWcfSTYm2Ztk2yG2J8n7u/8GW5M8b6lrXFBV\nLYsX82/q3gecBjwJ+FfgjIP2+X3gqm55LXDDtOueUD9fDPxkt/yGVvvZ7XcscDuwGZibdt0T+n6u\nBu4Eju/WnzHtuifUzw3AG7rlM4Ad0657hH6+CHgesO0Q288DPgUEeAHwhWnXXFXLakQ/zGMVLgCu\n65Y/BpydJEtY4zgs2s+q+mxVPdKtbmb+cwrLzbCPyfgL4F3Afy9lcWM0TD9fC3ygqr4DUFV7l7jG\ncRimnwX8VLf808C/L2F9Y1FVtwMPHWaXC4AP1rzNwHFJTlya6g5tOQX9MI9V+OE+VfUY8DDw9CWp\nbnyO9PERlzA/glhuFu1n92fvKVW1nB8IP8z383Tg9CT/nGRzknOWrLrxGaafbwNemWQn83fk/cHS\nlLakjsrHv/gPjyxjSV4JzAG/Mu1axi3JE4D3AhdPuZSlsIL56ZuzmP/r7PYkP1dV/zHVqsZvHXBt\nVV2R5BeBv03ynKp6fNqFtW45jegXfazC4D5JVjD/5+GDS1Ld+AzTT5K8BHgrcH5VPbpEtY3TYv08\nFngO8I9JdjA/37lpGb4hO8z3cyewqap+UFVfB77KfPAvJ8P08xLgRoCq+jzwE8w/H6YlQ/3/u9SW\nU9AP81iFTcBF3fJvA/9Q3Tsky8ii/UzyXOBvmA/55TifC4v0s6oerqqVVTVbVbPMvxdxflVtmU65\nIxvm5/bjzI/mSbKS+amc+5eyyDEYpp/fAM4GSPKzzAf9viWtcvI2Aa/u7r55AfBwVe2edlHLZuqm\nDvFYhSRvB7ZU1SbgGub/HNzO/Bsma6dX8WiG7Oe7gacCH+3ea/5GVZ0/taJHMGQ/l70h+/lp4KVJ\n7gH2A39aVcvqL9Eh+/km4Ookf8z8G7MXL7eBWJLrmf+lvLJ7r+Fy4IkAVXUV8+89nAdsBx4BXjOd\nSn+Un4yVpMYtp6kbSdIIDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhr3v/GFNTgSuHyX\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Aao6dR41Zr7O","colab_type":"code","outputId":"f2a339a6-8b1f-49c7-b9ee-f6ea598c1de2","executionInfo":{"status":"ok","timestamp":1558368297814,"user_tz":-480,"elapsed":2220,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["# Create the histogram\n","plt.hist(df['FTE'].dropna())\n","\n","# Add title and labels\n","plt.title('Distribution of %full-time \\n employee works')\n","plt.xlabel('% of full-time')\n","plt.ylabel('num employees')\n","\n","# Display the histogram\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOPYPUlgAhgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"QTfsChiyjfXR","colab_type":"text"},"source":["#### Looking at the datatypes"]},{"cell_type":"markdown","metadata":{"id":"JURYXqzMZ25I","colab_type":"text"},"source":["The data has been loaded into the workspace as df. Your job is to look at the DataFrame attribute .dtypes in the IPython Shell, and call its .value_counts() method in order to answer the question below.\n","\n","Make sure to call df.dtypes.value_counts(), and not df.value_counts()! Check out the difference in the Shell. df.value_counts() will return an error, because it is a Series method, not a DataFrame method."]},{"cell_type":"code","metadata":{"id":"PxpgT2gkZ7qP","colab_type":"code","outputId":"93d57229-2561-4d67-fe6e-291c0a895717","executionInfo":{"status":"ok","timestamp":1558368353565,"user_tz":-480,"elapsed":1028,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["df.dtypes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Function                   object\n","Use                        object\n","Sharing                    object\n","Reporting                  object\n","Student_Type               object\n","Position_Type              object\n","Object_Type                object\n","Pre_K                      object\n","Operating_Status           object\n","Object_Description         object\n","Text_2                     object\n","SubFund_Description        object\n","Job_Title_Description      object\n","Text_3                     object\n","Text_4                     object\n","Sub_Object_Description     object\n","Location_Description       object\n","FTE                       float64\n","Function_Description       object\n","Facility_or_Department     object\n","Position_Extra             object\n","Total                     float64\n","Program_Description        object\n","Fund_Description           object\n","Text_1                     object\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"zeIseGBYaARI","colab_type":"code","outputId":"d35acf32-03a7-4227-88aa-d301498068cf","executionInfo":{"status":"ok","timestamp":1558368357844,"user_tz":-480,"elapsed":1554,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["df.dtypes.value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["object     23\n","float64     2\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"29IjcK56aQrx","colab_type":"code","outputId":"979063ab-025b-454b-eb5e-02b411798e0d","executionInfo":{"status":"error","timestamp":1558368361564,"user_tz":-480,"elapsed":971,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["df.value_counts()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-986e25863b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'value_counts'"]}]},{"cell_type":"markdown","metadata":{"id":"moKaJJhg5Ft9","colab_type":"text"},"source":["**Encode the labels as categorical variables**\n","\n","There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take. The 9 labels have been loaded into a list called LABELS. In the Shell, check out the type for these labels using df[LABELS].dtypes.\n","\n","You will notice that every label is encoded as an object datatype. Because category datatypes are much more efficient your task is to convert the labels to category types using the .astype() method.\n","\n","Note: .astype() only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the .apply() method and provide a lambda function called categorize_label that applies .astype() to each column, x."]},{"cell_type":"code","metadata":{"id":"_23tzhA5jfO5","colab_type":"code","outputId":"746ae982-726e-489a-baa1-b35beb715c4f","executionInfo":{"status":"ok","timestamp":1558431786521,"user_tz":-480,"elapsed":1084,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["LABELS = ['Function',\n"," 'Use',\n"," 'Sharing',\n"," 'Reporting',\n"," 'Student_Type',\n"," 'Position_Type',\n"," 'Object_Type',\n"," 'Pre_K',\n"," 'Operating_Status']\n","LABELS"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Function',\n"," 'Use',\n"," 'Sharing',\n"," 'Reporting',\n"," 'Student_Type',\n"," 'Position_Type',\n"," 'Object_Type',\n"," 'Pre_K',\n"," 'Operating_Status']"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"664Hx2aT5Tlg","colab_type":"text"},"source":["Define the lambda function categorize_label to convert column x into x.astype('category')."]},{"cell_type":"code","metadata":{"id":"eQufRGvpjhnj","colab_type":"code","colab":{}},"source":["# Define the lambda function: categorize_label\n","categorize_label = lambda x: x.astype('category')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N94viJeT5c3m","colab_type":"code","colab":{}},"source":["# Convert df[LABELS] to a categorical type\n","df[LABELS] = df[LABELS].apply(categorize_label, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8fOcVQ55fyx","colab_type":"code","outputId":"70edfecb-48fa-41d9-fb4c-cac40bef3325","executionInfo":{"status":"ok","timestamp":1558419898200,"user_tz":-480,"elapsed":749,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Print the converted dtypes\n","print(df[LABELS].dtypes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Function            category\n","Use                 category\n","Sharing             category\n","Reporting           category\n","Student_Type        category\n","Position_Type       category\n","Object_Type         category\n","Pre_K               category\n","Operating_Status    category\n","dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CZ0s-qDP5o35","colab_type":"text"},"source":["**Counting unique labels**\n","\n"]},{"cell_type":"code","metadata":{"id":"dyn2mCoS7hr8","colab_type":"code","colab":{}},"source":["# Calculate number of unique values for each label: num_unique_labels\n","num_unique_labels = df[LABELS].apply(pd.Series.nunique)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bcrusN_7jb9","colab_type":"code","outputId":"8c0b1081-b1c7-4e83-a512-64c1cd954651","executionInfo":{"status":"ok","timestamp":1558368965187,"user_tz":-480,"elapsed":909,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":362}},"source":["# Plot number of unique values for each label\n","num_unique_labels.plot(kind='bar')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fc97f805a90>"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAFICAYAAABA2wWFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"bkMvoDGn7k_c","colab_type":"code","outputId":"296c857a-c5db-49a8-d4e1-ef5eb7d91df9","executionInfo":{"status":"ok","timestamp":1558368982757,"user_tz":-480,"elapsed":814,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["# Plot number of unique values for each label\n","num_unique_labels.plot(kind='bar')\n","\n","# Label the axes\n","plt.xlabel('Labels')\n","plt.ylabel('Number of unique values')\n","\n","# Display the plot\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAFWCAYAAABkVZqwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wP+nQyTNYu/AgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"EQrl89S5jhta","colab_type":"text"},"source":["#### Computing log loss with NumPy\n","\n","To see how the log loss metric handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function compute_log_loss().\n","\n","5 one-dimensional numeric arrays simulating different types of predictions have been pre-loaded: actual_labels, correct_confident, correct_not_confident, wrong_not_confident, and wrong_confident.\n","\n","Your job is to compute the log loss for each sample set provided using the compute_log_loss(predicted_values, actual_values). It takes the predicted values as the first argument and the actual values as the second argument."]},{"cell_type":"code","metadata":{"id":"EbT1RyLj9ETV","colab_type":"code","colab":{}},"source":["actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n","\n","correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n","\n","correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n","\n","wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n","\n","wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVolnPRX9nHf","colab_type":"code","colab":{}},"source":["def compute_log_loss(predicted, actual, eps=1e-14):\n","    \"\"\" Computes the logarithmic loss between `predicted` and `actual` when these are 1D arrays.\n","    \"\"\"\n","    predicted = np.clip(predicted, eps, 1 - eps)\n","    \n","    return -1 * np.mean(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ZYCP1WSjkka","colab_type":"code","outputId":"b7642f37-2fec-4dae-8bd2-3da42050442e","executionInfo":{"status":"ok","timestamp":1558368995993,"user_tz":-480,"elapsed":769,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compute and print log loss for 1st case\n","correct_confident = compute_log_loss(correct_confident, actual_labels)\n","print(\"Log loss, correct and confident: {}\".format(correct_confident)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log loss, correct and confident: 0.05129329438755058\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OIadLuAW-ZUy","colab_type":"code","outputId":"1db7ef9b-caea-4df0-fda4-3ae4deee0280","executionInfo":{"status":"ok","timestamp":1558368998763,"user_tz":-480,"elapsed":910,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compute log loss for 2nd case\n","correct_not_confident = compute_log_loss(correct_not_confident, actual_labels)\n","print(\"Log loss, correct and not confident: {}\".format(correct_not_confident)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log loss, correct and not confident: 0.4307829160924542\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r8qDkoT8-aqs","colab_type":"code","outputId":"980f531d-5408-47d4-a80f-96cfb4c08544","executionInfo":{"status":"ok","timestamp":1558369000403,"user_tz":-480,"elapsed":1030,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compute and print log loss for 3rd case\n","wrong_not_confident = compute_log_loss(wrong_not_confident, actual_labels)\n","print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log loss, wrong and not confident: 1.049822124498678\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CvMvitia-bya","colab_type":"code","outputId":"27b49595-1f95-455e-e2c9-9104b65fb50d","executionInfo":{"status":"ok","timestamp":1558369003169,"user_tz":-480,"elapsed":797,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compute and print log loss for 4th case\n","wrong_confident = compute_log_loss(wrong_confident, actual_labels)\n","print(\"Log loss, wrong and confident: {}\".format(wrong_confident)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log loss, wrong and confident: 2.9957322735539904\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZhDgOmYk-dLA","colab_type":"code","outputId":"7d8d63dc-ace6-4f21-a38c-d59d642b823b","executionInfo":{"status":"ok","timestamp":1558369004583,"user_tz":-480,"elapsed":768,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compute and print log loss for actual labels\n","actual_labels = compute_log_loss(actual_labels, actual_labels)\n","print(\"Log loss, actual labels: {}\".format(actual_labels)) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log loss, actual labels: 9.99200722162646e-15\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"688AwIAAjLej","colab_type":"text"},"source":["## 2. Creating a simple first model"]},{"cell_type":"markdown","metadata":{"id":"6I5WCL7JjmEg","colab_type":"text"},"source":["#### It's time to build a model"]},{"cell_type":"markdown","metadata":{"id":"pXGs1ITj-mya","colab_type":"text"},"source":["The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split: multilabel_train_test_split.\n","\n","You'll start with a simple model that uses just the numeric columns of your DataFrame when calling multilabel_train_test_split. The data has been read into a DataFrame df and a list consisting of just the numeric columns is available as NUMERIC_COLUMNS."]},{"cell_type":"code","metadata":{"id":"LzLLQLX1jOR4","colab_type":"code","colab":{}},"source":["def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n","    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n","        returns (X_train, X_test, Y_train, Y_test) where all\n","        classes in Y are represented at least `min_count` times.\n","    \"\"\"\n","    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n","\n","    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)    \n","    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n","    \n","    test_set_mask = index.isin(test_set_idxs)\n","    train_set_mask = ~test_set_mask\n","    \n","    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ-H4aaULior","colab_type":"code","colab":{}},"source":["def multilabel_sample(y, size=1000, min_count=5, seed=None):\n","    \"\"\" Takes a matrix of binary labels `y` and returns\n","        the indices for a sample of size `size` if\n","        `size` > 1 or `size` * len(y) if size =< 1.\n","        \n","        The sample is guaranteed to have > `min_count` of\n","        each label.\n","    \"\"\"\n","    try:\n","        if (np.unique(y).astype(int) != np.array([0, 1])).all():\n","            raise ValueError()\n","    except (TypeError, ValueError):\n","        raise ValueError('multilabel_sample only works with binary indicator matrices')\n","    \n","    if (y.sum(axis=0) < min_count).any():\n","        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n","    \n","    if size <= 1:\n","        size = np.floor(y.shape[0] * size)\n","    \n","    if y.shape[1] * min_count > size:\n","        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n","        # warn(msg.format(y.shape[1] * min_count, size))\n","        size = y.shape[1] * min_count\n","    \n","    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n","    \n","    if isinstance(y, pd.DataFrame):\n","        choices = y.index\n","        y = y.values\n","    else:\n","        choices = np.arange(y.shape[0])\n","    \n","    sample_idxs = np.array([], dtype=choices.dtype)\n","    \n","    # first, guarantee > min_count of each label\n","    for j in range(y.shape[1]):\n","        label_choices = choices[y[:, j] == 1]\n","        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n","        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n","        \n","    sample_idxs = np.unique(sample_idxs)\n","        \n","    # now that we have at least min_count of each, we can just random sample\n","    sample_count = size - sample_idxs.shape[0]\n","    \n","    # get sample_count indices from remaining choices\n","    remaining_choices = np.setdiff1d(choices, sample_idxs)\n","    remaining_sampled = rng.choice(remaining_choices, size=sample_count, replace=False)\n","        \n","    return np.concatenate([sample_idxs, remaining_sampled])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WrglRDGiHrE_","colab_type":"text"},"source":["\n","\n","*   Create a new DataFrame named numeric_data_only by applying the .fillna(-1000) method to the numeric columns (available in the list NUMERIC_COLUMNS) of df.\n","\n","*   Convert the labels (available in the list LABELS) to dummy variables. Save the result as label_dummies.\n","\n","*   In the call to multilabel_train_test_split(), set the size of your test set to be 0.2. Use a seed of 123.\n","\n","\n","*   Fill in the .info() method calls for X_train, X_test, y_train, and y_test.\n","\n"]},{"cell_type":"code","metadata":{"id":"DFBGai6DJcB9","colab_type":"code","colab":{}},"source":["NUMERIC_COLUMNS = ['FTE', 'Total']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRbcHzHQH2rf","colab_type":"code","colab":{}},"source":["# Create the new DataFrame: numeric_data_only\n","numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSxfX5XHJWAF","colab_type":"code","colab":{}},"source":["# Get labels and convert to dummy variables: label_dummies\n","label_dummies = pd.get_dummies(df[LABELS])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s10LVGY-xkOJ","colab_type":"code","outputId":"2c424e8c-a39f-408f-98f7-76a567847251","executionInfo":{"status":"ok","timestamp":1558431827811,"user_tz":-480,"elapsed":952,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":352}},"source":["label_dummies.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Function_Aides Compensation</th>\n","      <th>Function_Career &amp; Academic Counseling</th>\n","      <th>Function_Communications</th>\n","      <th>Function_Curriculum Development</th>\n","      <th>Function_Data Processing &amp; Information Services</th>\n","      <th>Function_Development &amp; Fundraising</th>\n","      <th>Function_Enrichment</th>\n","      <th>Function_Extended Time &amp; Tutoring</th>\n","      <th>Function_Facilities &amp; Maintenance</th>\n","      <th>Function_Facilities Planning</th>\n","      <th>Function_Finance, Budget, Purchasing &amp; Distribution</th>\n","      <th>Function_Food Services</th>\n","      <th>Function_Governance</th>\n","      <th>Function_Human Resources</th>\n","      <th>Function_Instructional Materials &amp; Supplies</th>\n","      <th>Function_Insurance</th>\n","      <th>Function_Legal</th>\n","      <th>Function_Library &amp; Media</th>\n","      <th>Function_NO_LABEL</th>\n","      <th>Function_Other Compensation</th>\n","      <th>Function_Other Non-Compensation</th>\n","      <th>Function_Parent &amp; Community Relations</th>\n","      <th>Function_Physical Health &amp; Services</th>\n","      <th>Function_Professional Development</th>\n","      <th>Function_Recruitment</th>\n","      <th>Function_Research &amp; Accountability</th>\n","      <th>Function_School Administration</th>\n","      <th>Function_School Supervision</th>\n","      <th>Function_Security &amp; Safety</th>\n","      <th>Function_Social &amp; Emotional</th>\n","      <th>Function_Special Population Program Management &amp; Support</th>\n","      <th>Function_Student Assignment</th>\n","      <th>Function_Student Transportation</th>\n","      <th>Function_Substitute Compensation</th>\n","      <th>Function_Teacher Compensation</th>\n","      <th>Function_Untracked Budget Set-Aside</th>\n","      <th>Function_Utilities</th>\n","      <th>Use_Business Services</th>\n","      <th>Use_ISPD</th>\n","      <th>Use_Instruction</th>\n","      <th>...</th>\n","      <th>Position_Type_Club Advisor/Coach</th>\n","      <th>Position_Type_Coordinator/Manager</th>\n","      <th>Position_Type_Custodian</th>\n","      <th>Position_Type_Guidance Counselor</th>\n","      <th>Position_Type_Instructional Coach</th>\n","      <th>Position_Type_Librarian</th>\n","      <th>Position_Type_NO_LABEL</th>\n","      <th>Position_Type_Non-Position</th>\n","      <th>Position_Type_Nurse</th>\n","      <th>Position_Type_Nurse Aide</th>\n","      <th>Position_Type_Occupational Therapist</th>\n","      <th>Position_Type_Other</th>\n","      <th>Position_Type_Physical Therapist</th>\n","      <th>Position_Type_Principal</th>\n","      <th>Position_Type_Psychologist</th>\n","      <th>Position_Type_School Monitor/Security</th>\n","      <th>Position_Type_Sec/Clerk/Other Admin</th>\n","      <th>Position_Type_Social Worker</th>\n","      <th>Position_Type_Speech Therapist</th>\n","      <th>Position_Type_Substitute</th>\n","      <th>Position_Type_TA</th>\n","      <th>Position_Type_Teacher</th>\n","      <th>Position_Type_Vice Principal</th>\n","      <th>Object_Type_Base Salary/Compensation</th>\n","      <th>Object_Type_Benefits</th>\n","      <th>Object_Type_Contracted Services</th>\n","      <th>Object_Type_Equipment &amp; Equipment Lease</th>\n","      <th>Object_Type_NO_LABEL</th>\n","      <th>Object_Type_Other Compensation/Stipend</th>\n","      <th>Object_Type_Other Non-Compensation</th>\n","      <th>Object_Type_Rent/Utilities</th>\n","      <th>Object_Type_Substitute Compensation</th>\n","      <th>Object_Type_Supplies/Materials</th>\n","      <th>Object_Type_Travel &amp; Conferences</th>\n","      <th>Pre_K_NO_LABEL</th>\n","      <th>Pre_K_Non PreK</th>\n","      <th>Pre_K_PreK</th>\n","      <th>Operating_Status_Non-Operating</th>\n","      <th>Operating_Status_Operating, Not PreK-12</th>\n","      <th>Operating_Status_PreK-12 Operating</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>198</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>931</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1524</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 104 columns</p>\n","</div>"],"text/plain":["      Function_Aides Compensation  ...  Operating_Status_PreK-12 Operating\n","0                                  ...                                    \n","198                             0  ...                                   0\n","209                             0  ...                                   1\n","750                             0  ...                                   1\n","931                             0  ...                                   0\n","1524                            0  ...                                   0\n","\n","[5 rows x 104 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"ZLd7_a4FLZXj","colab_type":"code","colab":{}},"source":["# Create training and test sets\n","X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n","                                                               label_dummies,\n","                                                               size=0.2, \n","                                                               seed=123)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHen1F5bLxcq","colab_type":"code","outputId":"524222f3-6bfd-4e36-86c1-08baffb5f821","executionInfo":{"status":"ok","timestamp":1558371579167,"user_tz":-480,"elapsed":767,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"source":["# Print the info\n","print(\"X_train info:\")\n","print(X_train.info())\n","print(\"\\nX_test info:\")  \n","print(X_test.info())\n","print(\"\\ny_train info:\")  \n","print(y_train.info())\n","print(\"\\ny_test info:\")  \n","print(y_test.info()) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1040 entries, 198 to 101861\n","Data columns (total 2 columns):\n","FTE      1040 non-null float64\n","Total    1040 non-null float64\n","dtypes: float64(2)\n","memory usage: 24.4 KB\n","None\n","\n","X_test info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 520 entries, 209 to 448628\n","Data columns (total 2 columns):\n","FTE      520 non-null float64\n","Total    520 non-null float64\n","dtypes: float64(2)\n","memory usage: 12.2 KB\n","None\n","\n","y_train info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1040 entries, 198 to 101861\n","Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n","dtypes: uint8(104)\n","memory usage: 113.8 KB\n","None\n","\n","y_test info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 520 entries, 209 to 448628\n","Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n","dtypes: uint8(104)\n","memory usage: 56.9 KB\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6PKa3KesL4bj","colab_type":"text"},"source":["**Training a model**\n","\n","In this exercise, you will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the NUMERIC_COLUMNS of your feature data.\n","\n","Then you'll test and print the accuracy with the .score() method to see the results of training."]},{"cell_type":"code","metadata":{"id":"cVFVtSzKMwzB","colab_type":"code","colab":{}},"source":["# Import classifiers\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multiclass import OneVsRestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGoIxGl5NsZA","colab_type":"code","colab":{}},"source":["# Create the DataFrame: numeric_data_only\n","numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n","\n","# Get labels and convert to dummy variables: label_dummies\n","label_dummies = pd.get_dummies(df[LABELS])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVr33AcrGfmB","colab_type":"code","colab":{}},"source":["# Create training and test sets\n","X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n","                                                               label_dummies,\n","                                                               size=0.2, \n","                                                               seed=123)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yayotboNNwWw","colab_type":"code","outputId":"c2f21d06-bbd2-4a06-868b-c26f3fdbfacd","executionInfo":{"status":"ok","timestamp":1558431852318,"user_tz":-480,"elapsed":1671,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":3658}},"source":["# Instantiate the classifier: clf\n","clf = OneVsRestClassifier(LogisticRegression())\n","\n","# Fit the classifier to the training data\n","clf.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"K5zS4l9XN4dh","colab_type":"code","outputId":"100eadc8-48c3-4863-e2a7-b509ad726578","executionInfo":{"status":"ok","timestamp":1558431857539,"user_tz":-480,"elapsed":873,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Print the accuracy\n","print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hoXHGDnyjoAZ","colab_type":"text"},"source":["#### Making predictions"]},{"cell_type":"code","metadata":{"id":"eYHuTOw9NyFo","colab_type":"code","outputId":"19833431-f128-4333-c1d9-150b147573ae","executionInfo":{"status":"ok","timestamp":1558431860018,"user_tz":-480,"elapsed":810,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["# Load the holdout data: holdout\n","holdout = pd.read_csv('/content/ML with experts_holdout.csv', header=None, index_col=0)\n","holdout.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>237</th>\n","      <td>Personal Services - Teachers</td>\n","      <td>Instruction - Regular</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>TIME CARD CERTIFIEDAddl</td>\n","      <td>Alternative Schools Instruction</td>\n","      <td>175.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Purpose School</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","      <td>Extra Duty/Signing Bonus Pay</td>\n","      <td>Basic Educational Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General</td>\n","      <td>School</td>\n","      <td>NaN</td>\n","      <td>Instruction</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>43400.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>784</th>\n","      <td>OTHER PERSONAL SERVICES</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SUB TEACHER ALL</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>STAFF DEV AND INSTR MEDIA</td>\n","      <td>0.0</td>\n","      <td>INST STAFF TRAINING SVCS</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>75.1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>GENERAL FUND</td>\n","      <td>TEACHER TRAINING</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>TERMINAL LEAVE VACATION</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>INSPECTOR &amp; SERVICE TECHNICIAN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TRANSPORTATION</td>\n","      <td>0.0</td>\n","      <td>PUPIL TRANSPORTATION SERVICES</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5270.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>GENERAL FUND</td>\n","      <td>TERMINAL LEAVE</td>\n","    </tr>\n","    <tr>\n","      <th>2643</th>\n","      <td>Extra Duty/Signing Bonus Pay</td>\n","      <td>Undistributed</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Principal &amp; Asst. Principal Support</td>\n","      <td>Educator Quality</td>\n","      <td>NaN</td>\n","      <td>Curriculum &amp; Instructional Staff Development</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>44800.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                1   ...                16\n","0                                   ...                  \n","237   Personal Services - Teachers  ...               NaN\n","466   Extra Duty/Signing Bonus Pay  ...               NaN\n","784        OTHER PERSONAL SERVICES  ...  TEACHER TRAINING\n","1786       TERMINAL LEAVE VACATION  ...    TERMINAL LEAVE\n","2643  Extra Duty/Signing Bonus Pay  ...               NaN\n","\n","[5 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"ghjl20yxTOH3","colab_type":"code","colab":{}},"source":["holdout.columns = ['Object_Description', 'Program_Description', 'SubFund_Description',\n","       'Job_Title_Description', 'Facility_or_Department',\n","       'Sub_Object_Description', 'Location_Description', 'FTE',\n","       'Function_Description', 'Position_Extra', 'Text_4', 'Total', 'Text_2',\n","       'Text_3', 'Fund_Description', 'Text_1']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhobBOEpTF9J","colab_type":"code","outputId":"59702c8e-5ad7-41da-c502-31f9e103d54e","executionInfo":{"status":"ok","timestamp":1558431865330,"user_tz":-480,"elapsed":822,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["holdout.shape # (2000, 16)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 16)"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"FOpMhH0VjpbZ","colab_type":"code","outputId":"0dce2413-aa76-4091-9f27-56752d51b876","executionInfo":{"status":"ok","timestamp":1558431868241,"user_tz":-480,"elapsed":1198,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Generate predictions: predictions\n","predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py:297: RuntimeWarning: overflow encountered in exp\n","  np.exp(prob, prob)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u8Qb0445EwT3","colab_type":"code","outputId":"19f40aad-675a-4dca-b2a0-f06fda83fe83","executionInfo":{"status":"ok","timestamp":1558420067950,"user_tz":-480,"elapsed":756,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["predictions"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.1079074 , 0.05155436, 0.01898326, ..., 0.12862383, 0.03139241,\n","        0.85219561],\n","       [0.02387206, 0.01298916, 0.00898569, ..., 0.07905002, 0.01152483,\n","        0.9077235 ],\n","       [0.10793318, 0.05155978, 0.01898575, ..., 0.12865741, 0.0313865 ,\n","        0.85216843],\n","       ...,\n","       [0.09890108, 0.04965793, 0.01809724, ..., 0.11678721, 0.03368076,\n","        0.86188215],\n","       [0.0267376 , 0.01362103, 0.00951925, ..., 0.0890605 , 0.01060185,\n","        0.89956715],\n","       [0.10051272, 0.05000983, 0.01825765, ..., 0.11887591, 0.03325923,\n","        0.8601507 ]])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"SnkFn7FWCuo8","colab_type":"text"},"source":["**Writing out your results to a csv for submission**\n","\n","To do this, you'll use your predictions values to create a new DataFrame, prediction_df.\n","\n","Interpreting LogLoss & Beating the Benchmark:\n","\n","When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: 2.0455, which merely submitted uniform probabilities for each class.\n","\n","Remember, the lower the log loss the better. Is your model's log loss lower than 2.0455?"]},{"cell_type":"code","metadata":{"id":"_XNaC5ATDLEL","colab_type":"code","colab":{}},"source":["# Format predictions in DataFrame: prediction_df\n","prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n","                             index=holdout.index,\n","                             data=predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSzdMMlUFlmz","colab_type":"code","outputId":"7ddf8317-1ede-4091-e47f-23b3d8f2347f","executionInfo":{"status":"ok","timestamp":1558420288582,"user_tz":-480,"elapsed":777,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":352}},"source":["prediction_df.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Function_Aides Compensation</th>\n","      <th>Function_Career &amp; Academic Counseling</th>\n","      <th>Function_Communications</th>\n","      <th>Function_Curriculum Development</th>\n","      <th>Function_Data Processing &amp; Information Services</th>\n","      <th>Function_Development &amp; Fundraising</th>\n","      <th>Function_Enrichment</th>\n","      <th>Function_Extended Time &amp; Tutoring</th>\n","      <th>Function_Facilities &amp; Maintenance</th>\n","      <th>Function_Facilities Planning</th>\n","      <th>Function_Finance, Budget, Purchasing &amp; Distribution</th>\n","      <th>Function_Food Services</th>\n","      <th>Function_Governance</th>\n","      <th>Function_Human Resources</th>\n","      <th>Function_Instructional Materials &amp; Supplies</th>\n","      <th>Function_Insurance</th>\n","      <th>Function_Legal</th>\n","      <th>Function_Library &amp; Media</th>\n","      <th>Function_NO_LABEL</th>\n","      <th>Function_Other Compensation</th>\n","      <th>Function_Other Non-Compensation</th>\n","      <th>Function_Parent &amp; Community Relations</th>\n","      <th>Function_Physical Health &amp; Services</th>\n","      <th>Function_Professional Development</th>\n","      <th>Function_Recruitment</th>\n","      <th>Function_Research &amp; Accountability</th>\n","      <th>Function_School Administration</th>\n","      <th>Function_School Supervision</th>\n","      <th>Function_Security &amp; Safety</th>\n","      <th>Function_Social &amp; Emotional</th>\n","      <th>Function_Special Population Program Management &amp; Support</th>\n","      <th>Function_Student Assignment</th>\n","      <th>Function_Student Transportation</th>\n","      <th>Function_Substitute Compensation</th>\n","      <th>Function_Teacher Compensation</th>\n","      <th>Function_Untracked Budget Set-Aside</th>\n","      <th>Function_Utilities</th>\n","      <th>Use_Business Services</th>\n","      <th>Use_ISPD</th>\n","      <th>Use_Instruction</th>\n","      <th>...</th>\n","      <th>Position_Type_Club Advisor/Coach</th>\n","      <th>Position_Type_Coordinator/Manager</th>\n","      <th>Position_Type_Custodian</th>\n","      <th>Position_Type_Guidance Counselor</th>\n","      <th>Position_Type_Instructional Coach</th>\n","      <th>Position_Type_Librarian</th>\n","      <th>Position_Type_NO_LABEL</th>\n","      <th>Position_Type_Non-Position</th>\n","      <th>Position_Type_Nurse</th>\n","      <th>Position_Type_Nurse Aide</th>\n","      <th>Position_Type_Occupational Therapist</th>\n","      <th>Position_Type_Other</th>\n","      <th>Position_Type_Physical Therapist</th>\n","      <th>Position_Type_Principal</th>\n","      <th>Position_Type_Psychologist</th>\n","      <th>Position_Type_School Monitor/Security</th>\n","      <th>Position_Type_Sec/Clerk/Other Admin</th>\n","      <th>Position_Type_Social Worker</th>\n","      <th>Position_Type_Speech Therapist</th>\n","      <th>Position_Type_Substitute</th>\n","      <th>Position_Type_TA</th>\n","      <th>Position_Type_Teacher</th>\n","      <th>Position_Type_Vice Principal</th>\n","      <th>Object_Type_Base Salary/Compensation</th>\n","      <th>Object_Type_Benefits</th>\n","      <th>Object_Type_Contracted Services</th>\n","      <th>Object_Type_Equipment &amp; Equipment Lease</th>\n","      <th>Object_Type_NO_LABEL</th>\n","      <th>Object_Type_Other Compensation/Stipend</th>\n","      <th>Object_Type_Other Non-Compensation</th>\n","      <th>Object_Type_Rent/Utilities</th>\n","      <th>Object_Type_Substitute Compensation</th>\n","      <th>Object_Type_Supplies/Materials</th>\n","      <th>Object_Type_Travel &amp; Conferences</th>\n","      <th>Pre_K_NO_LABEL</th>\n","      <th>Pre_K_Non PreK</th>\n","      <th>Pre_K_PreK</th>\n","      <th>Operating_Status_Non-Operating</th>\n","      <th>Operating_Status_Operating, Not PreK-12</th>\n","      <th>Operating_Status_PreK-12 Operating</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>237</th>\n","      <td>0.107907</td>\n","      <td>0.051554</td>\n","      <td>0.018983</td>\n","      <td>0.038208</td>\n","      <td>0.036741</td>\n","      <td>0.028427</td>\n","      <td>0.063205</td>\n","      <td>0.058761</td>\n","      <td>0.112324</td>\n","      <td>0.021181</td>\n","      <td>0.050885</td>\n","      <td>0.087913</td>\n","      <td>0.026425</td>\n","      <td>0.034792</td>\n","      <td>0.051276</td>\n","      <td>0.017433</td>\n","      <td>0.016965</td>\n","      <td>0.035343</td>\n","      <td>0.135843</td>\n","      <td>0.028254</td>\n","      <td>0.015176</td>\n","      <td>0.041555</td>\n","      <td>0.146997</td>\n","      <td>0.077265</td>\n","      <td>0.017449</td>\n","      <td>0.027281</td>\n","      <td>0.067985</td>\n","      <td>0.051352</td>\n","      <td>0.054467</td>\n","      <td>0.111446</td>\n","      <td>0.047664</td>\n","      <td>0.032903</td>\n","      <td>0.096960</td>\n","      <td>0.152216</td>\n","      <td>0.168947</td>\n","      <td>0.022062</td>\n","      <td>0.024188</td>\n","      <td>0.074154</td>\n","      <td>0.144941</td>\n","      <td>0.499849</td>\n","      <td>...</td>\n","      <td>0.032838</td>\n","      <td>0.060645</td>\n","      <td>0.067658</td>\n","      <td>0.064788</td>\n","      <td>0.042720</td>\n","      <td>0.030919</td>\n","      <td>0.096129</td>\n","      <td>0.152234</td>\n","      <td>0.042712</td>\n","      <td>0.054413</td>\n","      <td>0.041076</td>\n","      <td>0.206819</td>\n","      <td>0.031196</td>\n","      <td>0.031841</td>\n","      <td>0.048078</td>\n","      <td>0.045943</td>\n","      <td>0.082989</td>\n","      <td>0.037354</td>\n","      <td>0.053316</td>\n","      <td>0.172741</td>\n","      <td>0.122047</td>\n","      <td>0.174405</td>\n","      <td>0.036788</td>\n","      <td>0.663861</td>\n","      <td>0.159156</td>\n","      <td>0.038976</td>\n","      <td>0.022836</td>\n","      <td>0.159420</td>\n","      <td>0.198730</td>\n","      <td>0.034779</td>\n","      <td>0.039602</td>\n","      <td>0.106906</td>\n","      <td>0.144436</td>\n","      <td>0.032347</td>\n","      <td>0.500027</td>\n","      <td>0.471728</td>\n","      <td>0.092642</td>\n","      <td>0.128624</td>\n","      <td>0.031392</td>\n","      <td>0.852196</td>\n","    </tr>\n","    <tr>\n","      <th>466</th>\n","      <td>0.023872</td>\n","      <td>0.012989</td>\n","      <td>0.008986</td>\n","      <td>0.037126</td>\n","      <td>0.013396</td>\n","      <td>0.005028</td>\n","      <td>0.035120</td>\n","      <td>0.019156</td>\n","      <td>0.040444</td>\n","      <td>0.005116</td>\n","      <td>0.012309</td>\n","      <td>0.026691</td>\n","      <td>0.007856</td>\n","      <td>0.014619</td>\n","      <td>0.045810</td>\n","      <td>0.014461</td>\n","      <td>0.012974</td>\n","      <td>0.025440</td>\n","      <td>0.100791</td>\n","      <td>0.004767</td>\n","      <td>0.015487</td>\n","      <td>0.010874</td>\n","      <td>0.051631</td>\n","      <td>0.070215</td>\n","      <td>0.007314</td>\n","      <td>0.009088</td>\n","      <td>0.043097</td>\n","      <td>0.021051</td>\n","      <td>0.019192</td>\n","      <td>0.024302</td>\n","      <td>0.022451</td>\n","      <td>0.009960</td>\n","      <td>0.025342</td>\n","      <td>0.040764</td>\n","      <td>0.059505</td>\n","      <td>0.024250</td>\n","      <td>0.016980</td>\n","      <td>0.078830</td>\n","      <td>0.111285</td>\n","      <td>0.227804</td>\n","      <td>...</td>\n","      <td>0.010879</td>\n","      <td>0.032080</td>\n","      <td>0.018922</td>\n","      <td>0.013078</td>\n","      <td>0.025404</td>\n","      <td>0.012459</td>\n","      <td>0.288478</td>\n","      <td>0.125121</td>\n","      <td>0.009971</td>\n","      <td>0.000000</td>\n","      <td>0.007537</td>\n","      <td>0.102249</td>\n","      <td>0.012520</td>\n","      <td>0.010373</td>\n","      <td>0.012117</td>\n","      <td>0.016342</td>\n","      <td>0.017170</td>\n","      <td>0.012498</td>\n","      <td>0.015815</td>\n","      <td>0.047598</td>\n","      <td>0.037570</td>\n","      <td>0.115299</td>\n","      <td>0.011098</td>\n","      <td>0.059018</td>\n","      <td>0.274706</td>\n","      <td>0.056565</td>\n","      <td>0.028730</td>\n","      <td>0.100195</td>\n","      <td>0.190380</td>\n","      <td>0.047887</td>\n","      <td>0.024557</td>\n","      <td>0.020679</td>\n","      <td>0.109966</td>\n","      <td>0.039890</td>\n","      <td>0.776891</td>\n","      <td>0.184392</td>\n","      <td>0.036267</td>\n","      <td>0.079050</td>\n","      <td>0.011525</td>\n","      <td>0.907723</td>\n","    </tr>\n","    <tr>\n","      <th>784</th>\n","      <td>0.107933</td>\n","      <td>0.051560</td>\n","      <td>0.018986</td>\n","      <td>0.038214</td>\n","      <td>0.036743</td>\n","      <td>0.028432</td>\n","      <td>0.063216</td>\n","      <td>0.058775</td>\n","      <td>0.112341</td>\n","      <td>0.021184</td>\n","      <td>0.050885</td>\n","      <td>0.087933</td>\n","      <td>0.026428</td>\n","      <td>0.034800</td>\n","      <td>0.051284</td>\n","      <td>0.017429</td>\n","      <td>0.016962</td>\n","      <td>0.035349</td>\n","      <td>0.135866</td>\n","      <td>0.028261</td>\n","      <td>0.015175</td>\n","      <td>0.041565</td>\n","      <td>0.147014</td>\n","      <td>0.077282</td>\n","      <td>0.017453</td>\n","      <td>0.027284</td>\n","      <td>0.067981</td>\n","      <td>0.051348</td>\n","      <td>0.054475</td>\n","      <td>0.111470</td>\n","      <td>0.047668</td>\n","      <td>0.032910</td>\n","      <td>0.096982</td>\n","      <td>0.152258</td>\n","      <td>0.168958</td>\n","      <td>0.022059</td>\n","      <td>0.024186</td>\n","      <td>0.074138</td>\n","      <td>0.144968</td>\n","      <td>0.499935</td>\n","      <td>...</td>\n","      <td>0.032845</td>\n","      <td>0.060642</td>\n","      <td>0.067668</td>\n","      <td>0.064793</td>\n","      <td>0.042727</td>\n","      <td>0.030924</td>\n","      <td>0.096127</td>\n","      <td>0.152253</td>\n","      <td>0.042720</td>\n","      <td>0.054628</td>\n","      <td>0.041083</td>\n","      <td>0.206836</td>\n","      <td>0.031201</td>\n","      <td>0.031844</td>\n","      <td>0.048089</td>\n","      <td>0.045951</td>\n","      <td>0.083005</td>\n","      <td>0.037361</td>\n","      <td>0.053327</td>\n","      <td>0.172790</td>\n","      <td>0.122074</td>\n","      <td>0.174415</td>\n","      <td>0.036786</td>\n","      <td>0.663841</td>\n","      <td>0.159185</td>\n","      <td>0.038969</td>\n","      <td>0.022836</td>\n","      <td>0.159427</td>\n","      <td>0.198772</td>\n","      <td>0.034776</td>\n","      <td>0.039602</td>\n","      <td>0.106937</td>\n","      <td>0.144463</td>\n","      <td>0.032351</td>\n","      <td>0.500012</td>\n","      <td>0.471737</td>\n","      <td>0.092664</td>\n","      <td>0.128657</td>\n","      <td>0.031386</td>\n","      <td>0.852168</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>0.106600</td>\n","      <td>0.051279</td>\n","      <td>0.018856</td>\n","      <td>0.037938</td>\n","      <td>0.036665</td>\n","      <td>0.028185</td>\n","      <td>0.062648</td>\n","      <td>0.058031</td>\n","      <td>0.111455</td>\n","      <td>0.021033</td>\n","      <td>0.050905</td>\n","      <td>0.086926</td>\n","      <td>0.026304</td>\n","      <td>0.034401</td>\n","      <td>0.050884</td>\n","      <td>0.017650</td>\n","      <td>0.017135</td>\n","      <td>0.035075</td>\n","      <td>0.134680</td>\n","      <td>0.027896</td>\n","      <td>0.015247</td>\n","      <td>0.041069</td>\n","      <td>0.146172</td>\n","      <td>0.076419</td>\n","      <td>0.017253</td>\n","      <td>0.027131</td>\n","      <td>0.068166</td>\n","      <td>0.051556</td>\n","      <td>0.054095</td>\n","      <td>0.110245</td>\n","      <td>0.047490</td>\n","      <td>0.032595</td>\n","      <td>0.095845</td>\n","      <td>0.150086</td>\n","      <td>0.168409</td>\n","      <td>0.022217</td>\n","      <td>0.024320</td>\n","      <td>0.074976</td>\n","      <td>0.143580</td>\n","      <td>0.495475</td>\n","      <td>...</td>\n","      <td>0.032451</td>\n","      <td>0.060834</td>\n","      <td>0.067115</td>\n","      <td>0.064491</td>\n","      <td>0.042392</td>\n","      <td>0.030629</td>\n","      <td>0.096259</td>\n","      <td>0.151287</td>\n","      <td>0.042319</td>\n","      <td>0.044427</td>\n","      <td>0.040726</td>\n","      <td>0.205976</td>\n","      <td>0.030916</td>\n","      <td>0.031662</td>\n","      <td>0.047528</td>\n","      <td>0.045552</td>\n","      <td>0.082141</td>\n","      <td>0.037015</td>\n","      <td>0.052720</td>\n","      <td>0.170286</td>\n","      <td>0.120686</td>\n","      <td>0.173857</td>\n","      <td>0.036873</td>\n","      <td>0.664904</td>\n","      <td>0.157710</td>\n","      <td>0.039379</td>\n","      <td>0.022848</td>\n","      <td>0.159061</td>\n","      <td>0.196625</td>\n","      <td>0.034944</td>\n","      <td>0.039607</td>\n","      <td>0.105336</td>\n","      <td>0.143071</td>\n","      <td>0.032133</td>\n","      <td>0.500815</td>\n","      <td>0.471255</td>\n","      <td>0.091557</td>\n","      <td>0.126921</td>\n","      <td>0.031695</td>\n","      <td>0.853576</td>\n","    </tr>\n","    <tr>\n","      <th>2643</th>\n","      <td>0.023785</td>\n","      <td>0.012969</td>\n","      <td>0.008969</td>\n","      <td>0.037054</td>\n","      <td>0.013388</td>\n","      <td>0.005016</td>\n","      <td>0.035032</td>\n","      <td>0.019087</td>\n","      <td>0.040351</td>\n","      <td>0.005106</td>\n","      <td>0.012310</td>\n","      <td>0.026603</td>\n","      <td>0.007846</td>\n","      <td>0.014573</td>\n","      <td>0.045713</td>\n","      <td>0.014510</td>\n","      <td>0.013010</td>\n","      <td>0.025387</td>\n","      <td>0.100544</td>\n","      <td>0.004750</td>\n","      <td>0.015507</td>\n","      <td>0.010838</td>\n","      <td>0.051542</td>\n","      <td>0.070001</td>\n","      <td>0.007291</td>\n","      <td>0.009074</td>\n","      <td>0.043130</td>\n","      <td>0.021075</td>\n","      <td>0.019154</td>\n","      <td>0.024223</td>\n","      <td>0.022428</td>\n","      <td>0.009933</td>\n","      <td>0.025255</td>\n","      <td>0.040586</td>\n","      <td>0.059446</td>\n","      <td>0.024297</td>\n","      <td>0.017005</td>\n","      <td>0.079068</td>\n","      <td>0.110986</td>\n","      <td>0.226959</td>\n","      <td>...</td>\n","      <td>0.010842</td>\n","      <td>0.032108</td>\n","      <td>0.018878</td>\n","      <td>0.013061</td>\n","      <td>0.025349</td>\n","      <td>0.012426</td>\n","      <td>0.288563</td>\n","      <td>0.124900</td>\n","      <td>0.009945</td>\n","      <td>0.000000</td>\n","      <td>0.007519</td>\n","      <td>0.102120</td>\n","      <td>0.012489</td>\n","      <td>0.010357</td>\n","      <td>0.012078</td>\n","      <td>0.016303</td>\n","      <td>0.017118</td>\n","      <td>0.012466</td>\n","      <td>0.015764</td>\n","      <td>0.047383</td>\n","      <td>0.037443</td>\n","      <td>0.115192</td>\n","      <td>0.011105</td>\n","      <td>0.059090</td>\n","      <td>0.274112</td>\n","      <td>0.056722</td>\n","      <td>0.028734</td>\n","      <td>0.100129</td>\n","      <td>0.189818</td>\n","      <td>0.047948</td>\n","      <td>0.024558</td>\n","      <td>0.020587</td>\n","      <td>0.109668</td>\n","      <td>0.039818</td>\n","      <td>0.777041</td>\n","      <td>0.184313</td>\n","      <td>0.036143</td>\n","      <td>0.078745</td>\n","      <td>0.011556</td>\n","      <td>0.907976</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 104 columns</p>\n","</div>"],"text/plain":["      Function_Aides Compensation  ...  Operating_Status_PreK-12 Operating\n","0                                  ...                                    \n","237                      0.107907  ...                            0.852196\n","466                      0.023872  ...                            0.907723\n","784                      0.107933  ...                            0.852168\n","1786                     0.106600  ...                            0.853576\n","2643                     0.023785  ...                            0.907976\n","\n","[5 rows x 104 columns]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"yxbb2YUVFWpn","colab_type":"code","colab":{}},"source":["# Save prediction_df to csv\n","prediction_df.to_csv('/content/predictions.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euIzDC4gFcJE","colab_type":"code","colab":{}},"source":["# Submit the predictions for scoring: score\n","score = score_submission(pred_path = 'predictions.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Kp1xh51FdmK","colab_type":"code","colab":{}},"source":["# Print score\n","print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZgEiACbjphI","colab_type":"text"},"source":["#### A very brief introduction to NLP\n","\n","\n","\n","\n","*   Tokenizing text:\n","> * Tokenization is the process of chopping up a character sequence into pieces called *tokens*.\n","> *  Often, tokens are separated by whitespace. But we can specify other delimiters as well. \n","\n","\n","*   List item\n","\n"]},{"cell_type":"code","metadata":{"id":"qvnoz-8jjsrs","colab_type":"code","colab":{}},"source":["one_grams = ['petro', 'vend', 'fuel', 'and', 'fluids']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HiTQ1jvFIGy-","colab_type":"text"},"source":["The sum of the sizes of 1-gram, 2-grams and 3-grams generated by the string above:\n","\n","5 + 4 + 3 = 12 "]},{"cell_type":"markdown","metadata":{"id":"P2dph-OzjtKE","colab_type":"text"},"source":["#### Representing text numerically"]},{"cell_type":"markdown","metadata":{"id":"PjJy1PkWI74p","colab_type":"text"},"source":["**Creating a bag-of-words in scikit-learn**\n","\n","In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\n","\n","You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label.\n","\n","Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n","\n"]},{"cell_type":"code","metadata":{"id":"wbvEGJpbH2l5","colab_type":"code","colab":{}},"source":["# Import CountVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I01_QvfDjvNE","colab_type":"code","colab":{}},"source":["# Create the token pattern: TOKENS_ALPHANUMERIC\n","TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-3AcHKPNG_F","colab_type":"text"},"source":["\n","\n","*   Fill missing values in df.Position_Extra using .fillna('') to replace NaNs with empty strings. Specify the additional keyword argument inplace=True so that you don't have to assign the result back to df.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"E8axnMgkOWr4","colab_type":"code","colab":{}},"source":["# Fill missing values in df.Position_Extra\n","df.Position_Extra.fillna('', inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CxPT8b3kPJWS","colab_type":"text"},"source":["\n","\n","*   Instantiate the CountVectorizer as vec_alphanumeric by specifying the token_pattern to be TOKENS_ALPHANUMERIC.\n","\n"]},{"cell_type":"code","metadata":{"id":"jt6gdvUFOYCq","colab_type":"code","outputId":"f7244daf-f9e6-47a9-bc04-887cb86fc743","executionInfo":{"status":"ok","timestamp":1558431882946,"user_tz":-480,"elapsed":898,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Instantiate the CountVectorizer: vec_alphanumeric\n","vec_alphanumeric = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)\n","\n","# Fit to the data\n","vec_alphanumeric.fit(df.Position_Extra, df.Position_Type)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","        strip_accents=None, token_pattern='[A-Za-z0-9]+(?=\\\\s+)',\n","        tokenizer=None, vocabulary=None)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"ry6SAiT2OaEQ","colab_type":"code","outputId":"bcbb4264-fce1-4dbb-ad7c-29d8a5618bef","executionInfo":{"status":"ok","timestamp":1558431885457,"user_tz":-480,"elapsed":926,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Print the number of tokens and first 15 tokens\n","msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n","print(msg.format(len(vec_alphanumeric.get_feature_names())))\n","print(vec_alphanumeric.get_feature_names()[:15])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are 110 tokens in Position_Extra if we split on non-alpha numeric\n","['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'assessment', 'assistant', 'asst', 'athletic', 'avg']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P9y_p_jBP9Uk","colab_type":"text"},"source":["Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!"]},{"cell_type":"markdown","metadata":{"id":"p8Me4g9YQMAd","colab_type":"text"},"source":["**Combining text columns for tokenization**\n","\n","In order to use all of the text across columns, you'll need a method to turn a list of strings into a single string.\n","\n","In this exercise, you'll complete the function definition combine_text_columns(). \n","\n","When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method."]},{"cell_type":"code","metadata":{"id":"O28WT0vpQbK9","colab_type":"code","colab":{}},"source":["# Define combine_text_columns()\n","def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n","    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n","    \n","    # Drop non-text columns that are in the df\n","    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n","    text_data = data_frame.drop(to_drop, axis = 1)\n","    \n","    # Replace nans with blanks\n","    text_data.fillna(\"\", inplace = True)\n","    \n","    # Join all text items in a row that have a space in between\n","    return text_data.apply(lambda x: \" \".join(x), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZmX-3QbyDEY","colab_type":"code","colab":{}},"source":["# Create the text vector\n","text_vector = combine_text_columns(df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RN_yH_F8P_Nn","colab_type":"code","colab":{}},"source":["# Import the CountVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vv0uS6nMx6fZ","colab_type":"code","colab":{}},"source":["# Create the basic token pattern\n","TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n","\n","# Create the alphanumeric token pattern\n","TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"222Qa3RgyAG4","colab_type":"code","colab":{}},"source":["# Instantiate basic CountVectorizer: vec_basic\n","vec_basic = CountVectorizer(token_pattern = TOKENS_BASIC)\n","\n","# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n","vec_alphanumeric = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lM8V8hc0yDDQ","colab_type":"code","outputId":"63b25baf-ff5a-4feb-d3c9-d17f57bf671f","executionInfo":{"status":"ok","timestamp":1558431956180,"user_tz":-480,"elapsed":857,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Fit and transform vec_basic\n","vec_basic.fit_transform(text_vector)\n","\n","# Print number of tokens of vec_basic\n","print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are 1389 tokens in the dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dJWf51WkyHyk","colab_type":"code","outputId":"9d310c90-3fe2-46d8-8f31-639e8721a287","executionInfo":{"status":"ok","timestamp":1558431964018,"user_tz":-480,"elapsed":847,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Fit and transform vec_alphanumeric\n","vec_alphanumeric.fit_transform(text_vector)\n","\n","# Print number of tokens of vec_alphanumeric\n","print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are 1087 alpha-numeric tokens in the dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E9oTVv0LjOXv","colab_type":"text"},"source":["## 3. Improving your model"]},{"cell_type":"markdown","metadata":{"id":"a8X4e02ajxos","colab_type":"text"},"source":["#### Pipelines, feature & text preprocessing\n","\n","n this exercise, your job is to instantiate a pipeline that trains using the numeric column of the sample data.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ECSKRh6h6b0V","colab_type":"code","colab":{}},"source":["# Import Pipeline\n","from sklearn.pipeline import Pipeline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjQCCmzi7W4G","colab_type":"code","colab":{}},"source":["# Import other necessary modules\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multiclass import OneVsRestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXokLfeM9hdL","colab_type":"code","outputId":"262f4c05-49ed-4afe-a576-dfd1ff1abfe3","executionInfo":{"status":"ok","timestamp":1558436308064,"user_tz":-480,"elapsed":1014,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["sample_df = pd.read_csv('/content/sample_df.csv', index_col=0)\n","print('df dimension:', sample_df.shape) # (1000, 4)\n","sample_df.head(5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["df dimension: (1000, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>numeric</th>\n","      <th>text</th>\n","      <th>with_missing</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-10.856306</td>\n","      <td>NaN</td>\n","      <td>4.433240</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9.973454</td>\n","      <td>foo</td>\n","      <td>4.310229</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.829785</td>\n","      <td>foo bar</td>\n","      <td>2.469828</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-15.062947</td>\n","      <td>NaN</td>\n","      <td>2.852981</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-5.786003</td>\n","      <td>foo bar</td>\n","      <td>1.826475</td>\n","      <td>a</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     numeric     text  with_missing label\n","0 -10.856306      NaN      4.433240     b\n","1   9.973454      foo      4.310229     b\n","2   2.829785  foo bar      2.469828     a\n","3 -15.062947      NaN      2.852981     b\n","4  -5.786003  foo bar      1.826475     a"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"DLu6NbCYjQgA","colab_type":"code","colab":{}},"source":["# Split and select numeric data only, no nans \n","X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n","                                                    pd.get_dummies(sample_df['label']), \n","                                                    random_state=22)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJTaY2q07hIp","colab_type":"code","colab":{}},"source":["# Instantiate Pipeline object: pl\n","pl = Pipeline([\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUz6cENW-Hs1","colab_type":"code","outputId":"68ee7843-dc90-4c1c-d8b8-3f94288f4ece","executionInfo":{"status":"ok","timestamp":1558435108053,"user_tz":-480,"elapsed":1063,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit the pipeline to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('clf', OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None))])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"EVHVwy5c-JRS","colab_type":"code","outputId":"de8666c9-13fe-4ca6-fdb9-3b1278ffc47c","executionInfo":{"status":"ok","timestamp":1558435114879,"user_tz":-480,"elapsed":833,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on sample data - numeric, no nans:  0.62\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G__oKwAs_Zla","colab_type":"text"},"source":["**Preprocessing numeric features**\n","\n","In this exercise you'll improve your pipeline a bit by using the Imputer() imputation transformer from scikit-learn to fill in missing values in your sample data.\n","\n","By default, the imputer transformer replaces NaNs with the mean value of the column. That's a good enough imputation strategy for the sample data, so you won't need to pass anything extra to the imputer."]},{"cell_type":"code","metadata":{"id":"iG06z7pD_kvX","colab_type":"code","colab":{}},"source":["# Import the Imputer object\n","from sklearn.preprocessing import Imputer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQeu125O_mGe","colab_type":"code","colab":{}},"source":["# Create training and test sets using only numeric data\n","X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n","                                                    pd.get_dummies(sample_df['label']), \n","                                                    random_state=456)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mFeR8Th_sEt","colab_type":"code","outputId":"1f7ad843-db61-4b99-890e-d60e6319b669","executionInfo":{"status":"ok","timestamp":1558435519271,"user_tz":-480,"elapsed":832,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Insantiate Pipeline object: pl\n","pl = Pipeline([\n","        ('imp', Imputer()),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qHtnk5Fi_ttl","colab_type":"code","outputId":"64cdbffe-e191-40b7-e547-318ace248548","executionInfo":{"status":"ok","timestamp":1558435526066,"user_tz":-480,"elapsed":819,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit the pipeline to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('imp', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None))])"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"id":"Llb7sMZl_vV2","colab_type":"code","outputId":"5b426fb7-dc3d-4ec8-f3c8-8d304e9c9860","executionInfo":{"status":"ok","timestamp":1558435532810,"user_tz":-480,"elapsed":760,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on sample data - all numeric, incl nans:  0.636\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QUzXeHbjj1dE","colab_type":"text"},"source":["#### Text features and feature unions"]},{"cell_type":"markdown","metadata":{"id":"ltROOA4Y_6E1","colab_type":"text"},"source":["**Preprocessing text features**\n","\n","Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the text column from the sample data.\n","\n","To preprocess the text, you'll turn to CountVectorizer() to generate a bag-of-words representation of the data, as in Chapter 2. Using the default arguments, add a (step, transform) tuple to the steps list in your pipeline.\n","\n","Make sure you select only the text column for splitting your training and test sets."]},{"cell_type":"code","metadata":{"id":"qyG9-8HDAHO5","colab_type":"code","colab":{}},"source":["# Import the CountVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JMmGJ6_nCI96","colab_type":"code","outputId":"681e03b4-8d8f-425f-ce5a-e92eb9ce5822","executionInfo":{"status":"ok","timestamp":1558436314849,"user_tz":-480,"elapsed":744,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["sample_df.tail(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>numeric</th>\n","      <th>text</th>\n","      <th>with_missing</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>995</th>\n","      <td>6.347631</td>\n","      <td>foo</td>\n","      <td>3.140256</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>10.699186</td>\n","      <td>bar</td>\n","      <td>NaN</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>-9.093270</td>\n","      <td>NaN</td>\n","      <td>4.132525</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>4.702637</td>\n","      <td>foo bar</td>\n","      <td>NaN</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>-11.114304</td>\n","      <td>foo bar</td>\n","      <td>1.963396</td>\n","      <td>b</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       numeric     text  with_missing label\n","995   6.347631      foo      3.140256     b\n","996  10.699186      bar           NaN     a\n","997  -9.093270      NaN      4.132525     b\n","998   4.702637  foo bar           NaN     a\n","999 -11.114304  foo bar      1.963396     b"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"pK3OP0rrBKsb","colab_type":"code","colab":{}},"source":["# remove nan\n","sample_df['text'] = sample_df['text'].fillna(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yl2wpKs-Bk9_","colab_type":"code","outputId":"bd57a1fd-36c3-4c16-b5a7-6c7983f94cbc","executionInfo":{"status":"ok","timestamp":1558436322253,"user_tz":-480,"elapsed":750,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["sample_df.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>numeric</th>\n","      <th>text</th>\n","      <th>with_missing</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-10.856306</td>\n","      <td></td>\n","      <td>4.433240</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9.973454</td>\n","      <td>foo</td>\n","      <td>4.310229</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.829785</td>\n","      <td>foo bar</td>\n","      <td>2.469828</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-15.062947</td>\n","      <td></td>\n","      <td>2.852981</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-5.786003</td>\n","      <td>foo bar</td>\n","      <td>1.826475</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>16.514365</td>\n","      <td></td>\n","      <td>2.764315</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>-24.266792</td>\n","      <td>foo bar</td>\n","      <td>3.024317</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>-4.289126</td>\n","      <td>foo</td>\n","      <td>2.596040</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>12.659363</td>\n","      <td></td>\n","      <td>2.496415</td>\n","      <td>a</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>-8.667404</td>\n","      <td>bar</td>\n","      <td>4.032080</td>\n","      <td>a</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     numeric     text  with_missing label\n","0 -10.856306               4.433240     b\n","1   9.973454      foo      4.310229     b\n","2   2.829785  foo bar      2.469828     a\n","3 -15.062947               2.852981     b\n","4  -5.786003  foo bar      1.826475     a\n","5  16.514365               2.764315     b\n","6 -24.266792  foo bar      3.024317     b\n","7  -4.289126      foo      2.596040     b\n","8  12.659363               2.496415     a\n","9  -8.667404      bar      4.032080     a"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"code","metadata":{"id":"R489raN8Al93","colab_type":"code","colab":{}},"source":["# Split out only the text data\n","X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n","                                                    pd.get_dummies(sample_df['label']), \n","                                                    random_state=456)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EeOV8OuAoHb","colab_type":"code","colab":{}},"source":["# Instantiate Pipeline object: pl\n","pl = Pipeline([\n","        ('vec', CountVectorizer()),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfhEFqIkAqOL","colab_type":"code","outputId":"062c5959-00fa-4ac9-c789-a53c12cc7a37","executionInfo":{"status":"ok","timestamp":1558436333801,"user_tz":-480,"elapsed":753,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","        strip_...te=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None))])"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"JYqEOORMj4YD","colab_type":"code","outputId":"74ba22ee-1c30-4cc1-b2af-b7700deca376","executionInfo":{"status":"ok","timestamp":1558436341885,"user_tz":-480,"elapsed":837,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on sample data - just text data: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on sample data - just text data:  0.808\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x3KzY8cFC5q3","colab_type":"text"},"source":["**Multiple types of processing: FunctionTransformer**\n","\n","Any step in the pipeline must be an object that implements the fit and transform methods. The FunctionTransformer creates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines.\n","\n","You'll create functions that separate the text from the numeric variables and see how the .fit() and .transform() methods work.\n","\n","\n","\n","*   Take entire DataFrame, return numeric columns\n","*   Take entire DataFrame, return text columns\n","\n"]},{"cell_type":"code","metadata":{"id":"-5NAlXO1DJJR","colab_type":"code","colab":{}},"source":["# Import FunctionTransformer\n","from sklearn.preprocessing import FunctionTransformer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGNhsknhEmLi","colab_type":"code","colab":{}},"source":["# Obtain the text data: get_text_data\n","get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n","\n","# Obtain the numeric data: get_numeric_data\n","get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ox7oVcaFBi1","colab_type":"code","colab":{}},"source":["# Fit and transform the text data: just_text_data\n","just_text_data = get_text_data.fit_transform(sample_df)\n","\n","# Fit and transform the numeric data: just_numeric_data\n","just_numeric_data = get_numeric_data.fit_transform(sample_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvFCGPkdFDhv","colab_type":"code","outputId":"a40110ad-ac87-45a1-9df2-96b285548d19","executionInfo":{"status":"ok","timestamp":1558436927047,"user_tz":-480,"elapsed":1087,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["# Print head to check results\n","print('Text Data')\n","print(just_text_data.head())\n","print('\\nNumeric Data')\n","print(just_numeric_data.head())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Text Data\n","0           \n","1        foo\n","2    foo bar\n","3           \n","4    foo bar\n","Name: text, dtype: object\n","\n","Numeric Data\n","     numeric  with_missing\n","0 -10.856306      4.433240\n","1   9.973454      4.310229\n","2   2.829785      2.469828\n","3 -15.062947      2.852981\n","4  -5.786003      1.826475\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KV0nFkkdFJOi","colab_type":"text"},"source":["**Multiple types of processing: FeatureUnion**\n","\n","You're ready to perform separate steps on text and numeric data by nesting pipelines and using `FeatureUnion()`\n","\n","These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. \n","\n","... In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. \n","\n","The results of those pipelines are joined using `FeatureUnion`."]},{"cell_type":"code","metadata":{"id":"fpRfjEfrGGIt","colab_type":"code","colab":{}},"source":["# Import FeatureUnion\n","from sklearn.pipeline import FeatureUnion"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxk0igsCGxIr","colab_type":"code","colab":{}},"source":["# Split using ALL data in sample_df\n","X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n","                                                    pd.get_dummies(sample_df['label']), \n","                                                    random_state=22)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnNB-TyQGy4f","colab_type":"code","outputId":"4bcb9dba-7128-4a57-9522-f26bb0bd99bb","executionInfo":{"status":"ok","timestamp":1558437383011,"user_tz":-480,"elapsed":803,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Create a FeatureUnion with nested pipeline: process_and_join_features\n","process_and_join_features = FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer())\n","                ]))\n","             ]\n","        )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"S39W7JQdG1BK","colab_type":"code","colab":{}},"source":["# Instantiate nested pipeline: pl\n","pl = Pipeline([\n","        ('union', process_and_join_features),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EERk0xuFG24Y","colab_type":"code","outputId":"19178a06-220d-4814-9cbf-f96b734bfe3a","executionInfo":{"status":"ok","timestamp":1558437398603,"user_tz":-480,"elapsed":950,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit pl to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('union', FeatureUnion(n_jobs=None,\n","       transformer_list=[('numeric_features', Pipeline(memory=None,\n","     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n","          func=<function <lambda> at 0x7fdef7bb7730>, inv_kw_args=None,\n","          inverse_func=None, kw...te=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None))])"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"code","metadata":{"id":"Zo6G5IhIG4fA","colab_type":"code","outputId":"2e86d64d-9278-41aa-d44b-c8b5f9926068","executionInfo":{"status":"ok","timestamp":1558437405874,"user_tz":-480,"elapsed":773,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on sample data - all data: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on sample data - all data:  0.928\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A8ERLu9cj4ej","colab_type":"text"},"source":["#### Choosing a classification model"]},{"cell_type":"markdown","metadata":{"id":"ohAm3aI_G9eq","colab_type":"text"},"source":["**Using FunctionTransformer on the main dataset**\n","\n","In this exercise you're going to use FunctionTransformer on the primary budget data, before instantiating a multiple-datatype pipeline in the next exercise."]},{"cell_type":"code","metadata":{"id":"ghwKERw_HFdv","colab_type":"code","outputId":"a1e6a19a-ee5c-4689-8f79-28ab1b16d89a","executionInfo":{"status":"ok","timestamp":1558437460427,"user_tz":-480,"elapsed":832,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df.shape # (1560, 25)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1560, 25)"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"voMBoo4WHJsv","colab_type":"code","outputId":"7f63312d-04eb-4bd3-e276-986a64f6981b","executionInfo":{"status":"ok","timestamp":1558437474336,"user_tz":-480,"elapsed":870,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["df.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Function</th>\n","      <th>Use</th>\n","      <th>Sharing</th>\n","      <th>Reporting</th>\n","      <th>Student_Type</th>\n","      <th>Position_Type</th>\n","      <th>Object_Type</th>\n","      <th>Pre_K</th>\n","      <th>Operating_Status</th>\n","      <th>Object_Description</th>\n","      <th>Text_2</th>\n","      <th>SubFund_Description</th>\n","      <th>Job_Title_Description</th>\n","      <th>Text_3</th>\n","      <th>Text_4</th>\n","      <th>Sub_Object_Description</th>\n","      <th>Location_Description</th>\n","      <th>FTE</th>\n","      <th>Function_Description</th>\n","      <th>Facility_or_Department</th>\n","      <th>Position_Extra</th>\n","      <th>Total</th>\n","      <th>Program_Description</th>\n","      <th>Fund_Description</th>\n","      <th>Text_1</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>198</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplemental *</td>\n","      <td>NaN</td>\n","      <td>Operation and Maintenance of Plant Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Non-Certificated Salaries And Wages</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Care and Upkeep of Building Services</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-8290.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I CARRYOVER</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>Student Transportation</td>\n","      <td>NO_LABEL</td>\n","      <td>Shared Services</td>\n","      <td>Non-School</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Other Non-Compensation</td>\n","      <td>NO_LABEL</td>\n","      <td>PreK-12 Operating</td>\n","      <td>REPAIR AND MAINTENANCE SERVICES</td>\n","      <td>NaN</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ADMIN. SERVICES</td>\n","      <td>NaN</td>\n","      <td>STUDENT TRANSPORT SERVICE</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>618.00</td>\n","      <td>PUPIL TRANSPORTATION</td>\n","      <td>General Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>Teacher Compensation</td>\n","      <td>Instruction</td>\n","      <td>School Reported</td>\n","      <td>School</td>\n","      <td>Unspecified</td>\n","      <td>Teacher</td>\n","      <td>Base Salary/Compensation</td>\n","      <td>Non PreK</td>\n","      <td>PreK-12 Operating</td>\n","      <td>Personal Services - Teachers</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TCHER 5TH GRADE</td>\n","      <td>NaN</td>\n","      <td>Regular Instruction</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>TEACHER</td>\n","      <td>49800.00</td>\n","      <td>Instruction - Regular</td>\n","      <td>General Purpose School</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>931</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>General Supplies</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Instruction</td>\n","      <td>Instruction And Curriculum</td>\n","      <td></td>\n","      <td>-1.02</td>\n","      <td>\"Title I, Part A Schoolwide Activities Related...</td>\n","      <td>General Operating Fund</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1524</th>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>NO_LABEL</td>\n","      <td>Non-Operating</td>\n","      <td>Supplies and Materials</td>\n","      <td>NaN</td>\n","      <td>Community Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Supplies And Materials</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Other Community Services *</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>2300.00</td>\n","      <td>NaN</td>\n","      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n","      <td>TITLE I PI+HOMELESS</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Function  ...               Text_1\n","0                             ...                     \n","198                 NO_LABEL  ...    TITLE I CARRYOVER\n","209   Student Transportation  ...                  NaN\n","750     Teacher Compensation  ...                  NaN\n","931                 NO_LABEL  ...                  NaN\n","1524                NO_LABEL  ...  TITLE I PI+HOMELESS\n","\n","[5 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"markdown","metadata":{"id":"dk31VovVG9da","colab_type":"text"},"source":["\n","\n","*   Complete the call to multilabel_train_test_split() by selecting df[NON_LABELS].\n","\n","*   Compute get_text_data by using FunctionTransformer() and passing in combine_text_columns. Be sure to also specify validate=False.\n","\n","*   se FunctionTransformer() to compute get_numeric_data. In the lambda function, select out the NUMERIC_COLUMNS of x. Like you did when computing get_text_data, also specify validate=False.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"87vFoq5_HUdR","colab_type":"code","outputId":"c569666b-7821-437b-b053-9ec6f4551506","executionInfo":{"status":"ok","timestamp":1558437694698,"user_tz":-480,"elapsed":761,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["NUMERIC_COLUMNS"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['FTE', 'Total']"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"9n3LOJT1HLKM","colab_type":"code","colab":{}},"source":["# Import FunctionTransformer\n","from sklearn.preprocessing import FunctionTransformer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBbeDxPlIM7G","colab_type":"code","outputId":"82d22eff-858c-456d-8874-c8a000d97448","executionInfo":{"status":"ok","timestamp":1558437756833,"user_tz":-480,"elapsed":768,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df[LABELS].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1560, 9)"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"code","metadata":{"id":"kw_pXbu-IJdD","colab_type":"code","colab":{}},"source":["# Get the dummy encoding of the labels\n","dummy_labels = pd.get_dummies(df[LABELS])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHPbas6sIRhp","colab_type":"code","colab":{}},"source":["# Get the columns that are features in the original df\n","NON_LABELS = [c for c in df.columns if c not in LABELS]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSjmABymIS0k","colab_type":"code","colab":{}},"source":["# Split into training and test sets\n","X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n","                                                               dummy_labels,\n","                                                               0.2, \n","                                                               seed=123)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n66yw41hIVKc","colab_type":"code","colab":{}},"source":["# Preprocess the text data: get_text_data\n","get_text_data = FunctionTransformer(combine_text_columns, validate=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-EE8HrIsj7Xg","colab_type":"code","colab":{}},"source":["# Preprocess the numeric data: get_numeric_data\n","get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7K05McI6IYuH","colab_type":"text"},"source":["**Add a model to the pipeline**\n","\n","You're about to take everything you've learned so far and implement it in a Pipeline.\n","\n","The structure of the pipeline is exactly the same as earlier in this chapter:\n","\n","\n","*   the preprocessing step uses FeatureUnion to join the results of nested pipelines that each rely on FunctionTransformer to select multiple datatypes\n","\n","*   the model step stores the model object\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"z_qvomQgIsym","colab_type":"code","outputId":"e621cee8-3b9d-4dc1-d491-86899022164f","executionInfo":{"status":"ok","timestamp":1558437979254,"user_tz":-480,"elapsed":911,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Complete the pipeline: pl\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer())\n","                ]))\n","             ]\n","        )),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u9wCNlJ7JGQO","colab_type":"code","outputId":"b11f9f0f-33c7-4769-947c-fc39e3603a1c","executionInfo":{"status":"ok","timestamp":1558437988808,"user_tz":-480,"elapsed":2925,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('union', FeatureUnion(n_jobs=None,\n","       transformer_list=[('numeric_features', Pipeline(memory=None,\n","     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n","          func=<function <lambda> at 0x7fdef7c42400>, inv_kw_args=None,\n","          inverse_func=None, kw...te=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False),\n","          n_jobs=None))])"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"nAyv-hfyJIIa","colab_type":"code","outputId":"b44b4bdc-a7a9-48d7-bcdf-ba7bd1cc98e7","executionInfo":{"status":"ok","timestamp":1558437993133,"user_tz":-480,"elapsed":729,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on budget dataset: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on budget dataset:  0.19038461538461537\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LdCiJpP1JLGn","colab_type":"text"},"source":["**Try a different class of model**\n","\n","You'll swap out the logistic-regression model and replace it with a random forest classifier, which uses the statistics of an ensemble of decision trees to generate predictions."]},{"cell_type":"code","metadata":{"id":"yq6fARXGJfxW","colab_type":"code","colab":{}},"source":["# Import random forest classifer\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3pKVp5WJj5W","colab_type":"code","outputId":"4ebb6a24-90b7-453a-f9ac-2b12d08a8585","executionInfo":{"status":"ok","timestamp":1558438107967,"user_tz":-480,"elapsed":870,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Edit model step in pipeline\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer())\n","                ]))\n","             ]\n","        )),\n","        ('clf', RandomForestClassifier())\n","    ])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_HJitJSeJlpv","colab_type":"code","outputId":"b0391af1-ba86-49f9-e783-70968c804a02","executionInfo":{"status":"ok","timestamp":1558438114193,"user_tz":-480,"elapsed":1056,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# Fit to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","     steps=[('union', FeatureUnion(n_jobs=None,\n","       transformer_list=[('numeric_features', Pipeline(memory=None,\n","     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n","          func=<function <lambda> at 0x7fdef7c42400>, inv_kw_args=None,\n","          inverse_func=None, kw...obs=None,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False))])"]},"metadata":{"tags":[]},"execution_count":141}]},{"cell_type":"code","metadata":{"id":"nmli-qGlJnNA","colab_type":"code","outputId":"bde2f6da-5929-4b80-ef16-3e7b4083684c","executionInfo":{"status":"ok","timestamp":1558438120450,"user_tz":-480,"elapsed":993,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on budget dataset: \", accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Accuracy on budget dataset:  0.29615384615384616\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AED8JD8oJq61","colab_type":"text"},"source":["**Can you adjust the model or parameters to improve accuracy?**\n","\n","Try changing the parameter n_estimators of RandomForestClassifier(), whose default value is 10, to 15."]},{"cell_type":"code","metadata":{"id":"nMA6Xo9GJ0Ik","colab_type":"code","colab":{}},"source":["# Import RandomForestClassifier\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFRn-4i1rRGQ","colab_type":"code","colab":{}},"source":["# Add model step to pipeline: pl\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer())\n","                ]))\n","             ]\n","        )),\n","        ('clf', RandomForestClassifier(n_estimators=15))\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpX5zAujrWeW","colab_type":"code","colab":{}},"source":["# Fit to the training data\n","pl.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTrEvNkDrX8b","colab_type":"code","colab":{}},"source":["# Compute and print accuracy\n","accuracy = pl.score(X_test, y_test)\n","print(\"\\nAccuracy on budget dataset: \", accuracy)\n","\n","# Accuracy on budget dataset:  0.3211538461538462 "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqu_vf7OjQmf","colab_type":"text"},"source":["## 4. Learning from the experts"]},{"cell_type":"markdown","metadata":{"id":"MqAxHzgIj87v","colab_type":"text"},"source":["#### Learning from the expert: processing"]},{"cell_type":"markdown","metadata":{"id":"cZrIZRxkw_DI","colab_type":"text"},"source":["**Deciding what's a word**\n","\n","In this exercise, you will use CountVectorizer on the training data X_train (preloaded into the workspace) to see the effect of tokenization on punctuation.\n","\n","Remember, since CountVectorizer expects a vector, you'll need to use the preloaded function, combine_text_columns before fitting to the training data."]},{"cell_type":"code","metadata":{"id":"zYcOPMBpxZKQ","colab_type":"code","colab":{}},"source":["# load raw data\n","df = pd.read_csv('/content/ML with experts.csv', header=None, index_col=0)\n","df.columns = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type',\n","       'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status',\n","       'Object_Description', 'Text_2', 'SubFund_Description',\n","       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n","       'Location_Description', 'FTE', 'Function_Description',\n","       'Facility_or_Department', 'Position_Extra', 'Total',\n","       'Program_Description', 'Fund_Description', 'Text_1']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nGZtVjkiuIE","colab_type":"code","outputId":"af0f43cc-a61a-41b1-ce52-91da19d2a134","executionInfo":{"status":"ok","timestamp":1558596000397,"user_tz":-480,"elapsed":732,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# subset dataset to match to datacamp training set\n","\n","X = df[['Object_Description', 'Text_2', 'SubFund_Description',\n","       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n","       'Location_Description', 'FTE', 'Function_Description',\n","       'Facility_or_Department', 'Position_Extra', 'Total',\n","       'Program_Description', 'Fund_Description', 'Text_1']]\n","\n","print(\"X dataset dimension:\", X.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X dataset dimension: (1560, 16)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HH5BDI_7xEHl","colab_type":"code","outputId":"d8f1bbf8-1027-43d0-c138-c9fd42fbb00f","executionInfo":{"status":"ok","timestamp":1558596002856,"user_tz":-480,"elapsed":744,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y = df[['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type',\n","       'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']]\n","\n","print(\"y dataset dimension:\", y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y dataset dimension: (1560, 9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6MUoqlzQjS3e","colab_type":"code","outputId":"ed3e2330-b475-4c8d-b49f-69d5f39103d9","executionInfo":{"status":"ok","timestamp":1558596006940,"user_tz":-480,"elapsed":921,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# dummy code\n","\n","y_dummy = pd.get_dummies(y)\n","\n","print('y dummy dimension:', y_dummy.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y dummy dimension: (1560, 104)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOOz2QnPj_7Z","colab_type":"code","outputId":"29917fab-bbb2-48ae-b29a-ca58a1ebda85","executionInfo":{"status":"ok","timestamp":1558596399869,"user_tz":-480,"elapsed":736,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    X, y_dummy, test_size=312, random_state=1)\n","\n","print(\"X train size:\", X_train.shape)\n","print(\"X test size:\", X_test.shape)\n","print(\"y train size:\", y_train.shape)\n","print(\"y test size:\", y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X train size: (1248, 16)\n","X test size: (312, 16)\n","y train size: (1248, 104)\n","y test size: (312, 104)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iy4IK1Iilixy","colab_type":"code","colab":{}},"source":["# Import the CountVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9P07Q-nlwqs","colab_type":"code","colab":{}},"source":["NUMERIC_COLUMNS = ['FTE', 'Total']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q532AwFgl3Yw","colab_type":"code","colab":{}},"source":["LABELS = ['Function',\n"," 'Use',\n"," 'Sharing',\n"," 'Reporting',\n"," 'Student_Type',\n"," 'Position_Type',\n"," 'Object_Type',\n"," 'Pre_K',\n"," 'Operating_Status']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNq14lb6lknS","colab_type":"code","colab":{}},"source":["def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n","    \"\"\" Takes the dataset as read in, drops the non-feature, non-text columns and\n","        then combines all of the text columns into a single vector that has all of\n","        the text for a row.\n","        \n","        :param data_frame: The data as read in with read_csv (no preprocessing necessary)\n","        :param to_drop (optional): Removes the numeric and label columns by default.\n","    \"\"\"\n","    # drop non-text columns that are in the df\n","    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n","    text_data = data_frame.drop(to_drop, axis=1)\n","    \n","    # replace nans with blanks\n","    text_data.fillna(\"\", inplace=True)\n","    \n","    # joins all of the text items in a row (axis=1)\n","    # with a space in between\n","    return text_data.apply(lambda x: \" \".join(x), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUSZgWXfmRPi","colab_type":"text"},"source":["\n","\n","*   Create text_vector by preprocessing X_train using combine_text_columns. This is important, or else you won't get any tokens!\n","\n","*   Instantiate CountVectorizer as text_features. Specify the keyword argument token_pattern=TOKENS_ALPHANUMERIC.\n","*   Fit text_features to the text_vector.\n","\n","\n","*    To print the first 10 tokens.\n","\n"]},{"cell_type":"code","metadata":{"id":"AlA0qdo-l1Oc","colab_type":"code","colab":{}},"source":["# Create the text vector\n","text_vector = combine_text_columns(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"64Zcym6Xluxg","colab_type":"code","colab":{}},"source":["# Create the token pattern: TOKENS_ALPHANUMERIC\n","TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1GsB_BgmggE","colab_type":"code","colab":{}},"source":["# Instantiate the CountVectorizer: text_features\n","text_features = CountVectorizer(token_pattern = TOKENS_ALPHANUMERIC)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xbr0Z1nymh_a","colab_type":"code","outputId":"9de56773-ef8b-4702-8142-67165edc308b","executionInfo":{"status":"ok","timestamp":1558596700850,"user_tz":-480,"elapsed":780,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Fit text_features to the text vector\n","text_features.fit(text_vector)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","                strip_accents=None, token_pattern='[A-Za-z0-9]+(?=\\\\s+)',\n","                tokenizer=None, vocabulary=None)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"LCE3my5Rmkt4","colab_type":"code","outputId":"fd1719f6-677e-4670-f5e0-0cba44b1be7e","executionInfo":{"status":"ok","timestamp":1558596708200,"user_tz":-480,"elapsed":1080,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Print the first 10 tokens\n","print(text_features.get_feature_names()[:10])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['00a', '12', '1st', '2nd', '3rd', '4th', '5th', '70h', '8', 'a']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zcgbBi1sm3TS","colab_type":"text"},"source":["**N-gram range in scikit-learn**\n","\n","Special functions: You'll notice a couple of new steps provided in the pipeline in this and many of the remaining exercises. Specifically, the dim_red step following the vectorizer step , and the scale step preceeding the clf (classification) step.\n","\n","These have been added in order to account for the fact that you're using a reduced-size sample of the full dataset in this course. To make sure the models perform as the expert competition winner intended, we have to apply a dimensionality reduction technique, which is what the dim_red step does, and we have to scale the features to lie between -1 and 1, which is what the scale step does.\n","\n","The dim_red step uses a scikit-learn function called SelectKBest(), applying something called the chi-squared test to select the K \"best\" features. The scale step uses a scikit-learn function called MaxAbsScaler() in order to squash the relevant features into the interval -1 to 1."]},{"cell_type":"code","metadata":{"id":"yqLlErtInIL4","colab_type":"code","colab":{}},"source":["# Import pipeline\n","from sklearn.pipeline import Pipeline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qEXnDo5nwuX","colab_type":"code","colab":{}},"source":["# Import classifiers\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.multiclass import OneVsRestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3enOmJDNnyKu","colab_type":"code","colab":{}},"source":["# Import CountVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHgbcrRYnzaX","colab_type":"code","colab":{}},"source":["# Import other preprocessing modules\n","from sklearn.preprocessing import Imputer\n","from sklearn.feature_selection import chi2, SelectKBest"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KYNnIDFn0iu","colab_type":"code","colab":{}},"source":["# Import functional utilities\n","from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n","from sklearn.pipeline import FeatureUnion"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-K45QTnn3GK","colab_type":"code","colab":{}},"source":["# Select 300 best features\n","chi_k = 300"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnQsJWUxn4WY","colab_type":"code","colab":{}},"source":["# Perform preprocessing\n","get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n","get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Q8kXGUHn6JO","colab_type":"code","colab":{}},"source":["# Create the token pattern: TOKENS_ALPHANUMERIC\n","TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXRIlgX_n7e1","colab_type":"code","outputId":"67a9a3fd-cac8-4587-e550-9bf1cb7218ae","executionInfo":{"status":"ok","timestamp":1558597070050,"user_tz":-480,"elapsed":775,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Instantiate pipeline: pl\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n","                                                   ngram_range=(1, 2))),\n","                    ('dim_red', SelectKBest(chi2, chi_k))\n","                ]))\n","             ]\n","        )),\n","        ('scale', MaxAbsScaler()),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oV6sj9rmkAO3","colab_type":"text"},"source":["#### Learning from the expert: a stats trick"]},{"cell_type":"markdown","metadata":{"id":"R7LldTykoVXt","colab_type":"text"},"source":["**Implement interaction modeling in scikit-learn**\n","\n","It's time to add interaction features to your model. The PolynomialFeatures object in scikit-learn does just that, but here you're going to use a custom interaction object, SparseInteractions. Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.\n","\n","\n","\n","*   SparseInteractions does the same thing as PolynomialFeatures, but it uses sparse matrices to do so. \n","*   PolynomialFeatures and SparseInteractions both take the argument degree, which tells them what polynomial degree of interactions to compute.\n","\n"]},{"cell_type":"code","metadata":{"id":"qtJHrwmBohm4","colab_type":"code","colab":{}},"source":["# Instantiate pipeline: pl\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n","                                                   ngram_range=(1, 2))),  \n","                    ('dim_red', SelectKBest(chi2, chi_k))\n","                ]))\n","             ]\n","        )),\n","        # Add the interaction terms step below\n","        ('int', SparseInteractions(degree=2)), # make sure it is after the preprocessing step but before scaling\n","        ('scale', MaxAbsScaler()),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LQTAROd2kD2g","colab_type":"text"},"source":["#### Learning from the expert: a computational trick and the winning model"]},{"cell_type":"markdown","metadata":{"id":"6HSESd-uqTr6","colab_type":"text"},"source":["**Hashing Trick**\n","\n","Some problems are memory-bound and not easily parallelizable, and hashing enforces a fixed length computation instead of using a mutable datatype.\n","Enforcing a fixed length can speed up calculations drastically, especially on large datasets.\n","\n","In this exercise you will check out the scikit-learn implementation of HashingVectorizer before adding it to your pipeline later.\n","\n","\n","\n","*    it creates hash values from the text\n","\n"]},{"cell_type":"code","metadata":{"id":"hXx13p2aqv7R","colab_type":"code","outputId":"414e3135-1688-4e5d-962a-e1e05e1b1a21","executionInfo":{"status":"ok","timestamp":1558597850984,"user_tz":-480,"elapsed":908,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train.shape # X_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1248, 16)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"CFLK8cJkqEmK","colab_type":"code","colab":{}},"source":["# Import HashingVectorizer\n","from sklearn.feature_extraction.text import HashingVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzwH-_BEkDvu","colab_type":"code","colab":{}},"source":["# Get text data: text_data\n","text_data = combine_text_columns(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLZL7nT4rOF1","colab_type":"code","colab":{}},"source":["# Create the token pattern: TOKENS_ALPHANUMERIC\n","TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPn2JEy0rPZg","colab_type":"code","colab":{}},"source":["# Instantiate the HashingVectorizer: hashing_vec\n","hashing_vec = HashingVectorizer(token_pattern = TOKENS_ALPHANUMERIC)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQwYmw8qrQm0","colab_type":"code","colab":{}},"source":["# Fit and transform the Hashing Vectorizer\n","hashed_text = hashing_vec.fit_transform(text_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mu2SnUbjkJFq","colab_type":"code","outputId":"81a317af-ea00-44ae-dfae-b686440fa3ff","executionInfo":{"status":"ok","timestamp":1558597939077,"user_tz":-480,"elapsed":873,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Create DataFrame and print the head\n","hashed_df = pd.DataFrame(hashed_text.data)\n","print(hashed_df.head())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["          0\n","0 -0.150756\n","1  0.150756\n","2 -0.150756\n","3 -0.301511\n","4  0.150756\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tzxKPR0ArVAc","colab_type":"text"},"source":["\n","\n","*   All you need to do is add the HashingVectorizer step to the pipeline to replace the CountVectorizer step.\n","\n","\n","*   The parameters non_negative=True, norm=None, and binary=False make the HashingVectorizer perform similarly to the default settings on the CountVectorizer so you can just replace one with the other.\n","\n"]},{"cell_type":"code","metadata":{"id":"BkYiUy0ara3e","colab_type":"code","colab":{}},"source":["# Import the hashing vectorizer\n","from sklearn.feature_extraction.text import HashingVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCuBT7U6sCOd","colab_type":"code","colab":{}},"source":["# Class Imputer is deprecated\n","from sklearn.impute import SimpleImputer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJ8p51C1ruvi","colab_type":"code","outputId":"d7a38a15-49e9-4464-8b31-b08d3f50935f","executionInfo":{"status":"error","timestamp":1558598143493,"user_tz":-480,"elapsed":1322,"user":{"displayName":"Zhenna LU","photoUrl":"","userId":"13596549313510787594"}},"colab":{"base_uri":"https://localhost:8080/","height":285}},"source":["# Instantiate the winning model pipeline: pl\n","pl = Pipeline([\n","        ('union', FeatureUnion(\n","            transformer_list = [\n","                ('numeric_features', Pipeline([\n","                    ('selector', get_numeric_data),\n","                    ('imputer', Imputer())\n","                ])),\n","                ('text_features', Pipeline([\n","                    ('selector', get_text_data),\n","                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n","                                                     non_negative=True, \n","                                                     norm=None, binary=False,\n","                                                     ngram_range=(1, 2))),\n","                    ('dim_red', SelectKBest(chi2, chi_k))\n","                ]))\n","             ]\n","        )),\n","        ('int', SparseInteractions(degree=2)),\n","        ('scale', MaxAbsScaler()),\n","        ('clf', OneVsRestClassifier(LogisticRegression()))\n","    ])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-be58caf575a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                      \u001b[0mnon_negative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                      \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                                      ngram_range=(1, 2))),\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0;34m'dim_red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchi_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 ]))\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'non_negative'"]}]}]}